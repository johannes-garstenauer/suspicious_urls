{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e33345b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "data = scipy.io.loadmat('../../url.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9fc2f1",
   "metadata": {},
   "source": [
    "**create list for labels and data, where one entry is the data for the day with this index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e4fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_of_days = 120\n",
    "X, Y = [], []\n",
    "\n",
    "for i in range(num_of_days):\n",
    "    day_data = data[\"Day\" + str(i)]\n",
    "    X.append(day_data[0][0][0])\n",
    "    Y.append(day_data[0][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dd6d9c",
   "metadata": {},
   "source": [
    "**flatten y to not be a nested array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c247aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y-data are lists of numpy-arrays\n",
    "\n",
    "for i in range(len(Y)):\n",
    "    Y[i] = [element for sublist in Y[i] for element in sublist]\n",
    "   \n",
    "# y-data becomes a list of lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3124a360",
   "metadata": {},
   "source": [
    "### Train once on data for day 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1942485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC()\n",
    "\n",
    "clf.fit(X[0], Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "237bd468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "# takes a range of days (start until to)\n",
    "# fits the model with the data from the range until \"to\" itself\n",
    "# for day \"to\" for each url_batch the data is refitted (prevoius days data from range + all batches up to current)\n",
    "# and predicticed for the succesive batch of urls\n",
    "# returns the cumulative error rate for day \"to\"\n",
    "# batch_size determines the size of url_batches for which data is predicted and fitted on the \"to\" day\n",
    "def train_and_evaluate(start, to, clf, batch_size = 1):\n",
    "    \n",
    "    prev_x = X[0][0,:] #random row for initialization purposes, spliced off later before classifying\n",
    "    prev_y = []\n",
    "    for prev_day in range(start, to):\n",
    "        prev_x = vstack((prev_x, X[prev_day])) # stack up all matrices to previous day\n",
    "        prev_y = np.concatenate((prev_y, Y[prev_day])) # stack up all labels to previous day\n",
    "        \n",
    "        \n",
    "    # immediately splice off the first initial url used to initiate the matrix outside of the loop\n",
    "    url_indexes_without_initial = np.arange(1, prev_x.shape[0])\n",
    "    prev_x = prev_x.tocsr()[url_indexes_without_initial,:]\n",
    "    \n",
    "    # change X to row format for faster slicing row-wise.\n",
    "    curr_day_x = X[to].tocsr()\n",
    "    \n",
    "    # split the data in slices of batch_size\n",
    "    batches_amount = int(curr_day_x.shape[0] / batch_size)\n",
    "    curr_day_y = np.array_split(Y[to], batches_amount)\n",
    "    \n",
    "    err = 0\n",
    "    x_batches = X[0][0,:] #random row for initialization purposes, spliced off later before classifying\n",
    "    y_batches = []\n",
    "    for j in range(batches_amount): # looping through individual url-batches\n",
    "       \n",
    "        # Combine previous days data and all batches up until current\n",
    "        print(type(prev_x))\n",
    "        x_combined = vstack(prev_x, x_batches)\n",
    "        y_combined = prev_y.extend(y_batches.ravel())\n",
    "        \n",
    "        if (j == 0):\n",
    "            # immediately splice off the first initial url used to initiate the matrix outside of the loop\n",
    "            x_combined = x_combined[np.arange(1, x_combined.shape[0]),:]\n",
    "            \n",
    "        # Train for cumulated data excluding current batch\n",
    "        clf.fit(x_combined, y_combined)\n",
    "    \n",
    "        # splice current batch off\n",
    "        select_ind = np.arange(j * batch_size, (j+1) * batch_size)\n",
    "        curr_x_batch, curr_y_batch = curr_day_x[select_ind,:], curr_day_y[j] \n",
    "        \n",
    "        # Add current batch to cumulated list of batches\n",
    "        x_batches = vstack(x_batches, curr_x_batch)\n",
    "        y_batches.extend(curr_y_batch)\n",
    "        \n",
    "        # Predict for current batch\n",
    "        Y_preds = clf.predict(curr_x_batch)\n",
    "        \n",
    "        # if(j > 0):    \n",
    "        # Collect errors\n",
    "        # todo replace with accuracy score\n",
    "        for k in range(batch_size):\n",
    "            if(Y_preds[k] != curr_y_batch[k]):\n",
    "                err = err + 1\n",
    "        \n",
    "    \n",
    "        #clf.partial_fit(X_curr_url_batch, Y_curr_url_batch, classes=list(range(2))) # Continous fitting of urls and label\n",
    "\n",
    "        #print(\"Error-rate Day {}   : {}\".format(i,err / X_curr_day.shape[0]))\n",
    "    return err / curr_day_x.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9518013e",
   "metadata": {},
   "source": [
    "### Evaluate for all days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57040706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error-rate Day 1   : 0.02554999999999996\n",
      "Error-rate Day 2   : 0.019000000000000017\n",
      "Error-rate Day 3   : 0.021649999999999947\n",
      "Error-rate Day 4   : 0.026050000000000018\n",
      "Error-rate Day 5   : 0.023050000000000015\n",
      "Error-rate Day 6   : 0.02510000000000001\n",
      "Error-rate Day 7   : 0.030750000000000055\n",
      "Error-rate Day 8   : 0.028449999999999975\n",
      "Error-rate Day 9   : 0.03354999999999997\n",
      "Error-rate Day 10   : 0.03090000000000004\n",
      "Error-rate Day 11   : 0.02980000000000005\n",
      "Error-rate Day 12   : 0.023850000000000038\n",
      "Error-rate Day 13   : 0.019449999999999967\n",
      "Error-rate Day 14   : 0.026800000000000046\n",
      "Error-rate Day 15   : 0.0242\n",
      "Error-rate Day 16   : 0.027599999999999958\n",
      "Error-rate Day 17   : 0.022750000000000048\n",
      "Error-rate Day 18   : 0.023599999999999954\n",
      "Error-rate Day 19   : 0.021299999999999986\n",
      "Error-rate Day 20   : 0.026549999999999963\n",
      "Error-rate Day 21   : 0.03474999999999995\n",
      "Error-rate Day 22   : 0.03325\n",
      "Error-rate Day 23   : 0.03334999999999999\n",
      "Error-rate Day 24   : 0.03554999999999997\n",
      "Error-rate Day 25   : 0.035250000000000004\n",
      "Error-rate Day 26   : 0.02849999999999997\n",
      "Error-rate Day 27   : 0.030200000000000005\n",
      "Error-rate Day 28   : 0.029750000000000054\n",
      "Error-rate Day 29   : 0.028699999999999948\n",
      "Error-rate Day 30   : 0.03979999999999995\n",
      "Error-rate Day 31   : 0.03810000000000002\n",
      "Error-rate Day 32   : 0.034050000000000025\n",
      "Error-rate Day 33   : 0.03385000000000005\n",
      "Error-rate Day 34   : 0.030000000000000027\n",
      "Error-rate Day 35   : 0.04259999999999997\n",
      "Error-rate Day 36   : 0.03015000000000001\n",
      "Error-rate Day 37   : 0.028249999999999997\n",
      "Error-rate Day 38   : 0.05510000000000004\n",
      "Error-rate Day 39   : 0.05545\n",
      "Error-rate Day 40   : 0.03600000000000003\n",
      "Error-rate Day 41   : 0.028299999999999992\n",
      "Error-rate Day 42   : 0.036599999999999966\n",
      "Error-rate Day 43   : 0.043849999999999945\n",
      "Error-rate Day 44   : 0.02475000000000005\n",
      "Error-rate Day 45   : 0.023076923076923106\n",
      "Error-rate Day 46   : 0.035599999999999965\n",
      "Error-rate Day 47   : 0.03959999999999997\n",
      "Error-rate Day 48   : 0.05974999999999997\n",
      "Error-rate Day 49   : 0.06230000000000002\n",
      "Error-rate Day 50   : 0.044849999999999945\n",
      "Error-rate Day 51   : 0.03595000000000004\n",
      "Error-rate Day 52   : 0.03500000000000003\n",
      "Error-rate Day 53   : 0.04269999999999996\n",
      "Error-rate Day 54   : 0.031749999999999945\n",
      "Error-rate Day 55   : 0.024150000000000005\n",
      "Error-rate Day 56   : 0.025800000000000045\n",
      "Error-rate Day 57   : 0.0353\n",
      "Error-rate Day 58   : 0.029549999999999965\n",
      "Error-rate Day 59   : 0.028900000000000037\n",
      "Error-rate Day 60   : 0.03610000000000002\n",
      "Error-rate Day 61   : 0.03480000000000005\n",
      "Error-rate Day 62   : 0.04159999999999997\n",
      "Error-rate Day 63   : 0.04035\n",
      "Error-rate Day 64   : 0.038449999999999984\n",
      "Error-rate Day 65   : 0.036699999999999955\n",
      "Error-rate Day 66   : 0.03595000000000004\n",
      "Error-rate Day 67   : 0.03595000000000004\n",
      "Error-rate Day 68   : 0.03480000000000005\n",
      "Error-rate Day 69   : 0.02749999999999997\n",
      "Error-rate Day 70   : 0.03310000000000002\n",
      "Error-rate Day 71   : 0.029900000000000038\n",
      "Error-rate Day 72   : 0.029249999999999998\n",
      "Error-rate Day 73   : 0.03080000000000005\n",
      "Error-rate Day 74   : 0.029549999999999965\n",
      "Error-rate Day 75   : 0.03444999999999998\n",
      "Error-rate Day 76   : 0.03744999999999998\n",
      "Error-rate Day 77   : 0.026349999999999985\n",
      "Error-rate Day 78   : 0.03490000000000004\n",
      "Error-rate Day 79   : 0.039449999999999985\n",
      "Error-rate Day 80   : 0.03720000000000001\n",
      "Error-rate Day 81   : 0.03200000000000003\n",
      "Error-rate Day 82   : 0.03649999999999998\n",
      "Error-rate Day 83   : 0.03254999999999997\n",
      "Error-rate Day 84   : 0.03344999999999998\n",
      "Error-rate Day 85   : 0.04784999999999995\n",
      "Error-rate Day 86   : 0.03500000000000003\n",
      "Error-rate Day 87   : 0.03744999999999998\n",
      "Error-rate Day 88   : 0.03359999999999996\n",
      "Error-rate Day 89   : 0.047599999999999976\n",
      "Error-rate Day 90   : 0.04390000000000005\n",
      "Error-rate Day 91   : 0.035599999999999965\n",
      "Error-rate Day 92   : 0.04254999999999998\n",
      "Error-rate Day 93   : 0.04074999999999995\n",
      "Error-rate Day 94   : 0.036150000000000015\n",
      "Error-rate Day 95   : 0.01639999999999997\n",
      "Error-rate Day 96   : 0.02939999999999998\n",
      "Error-rate Day 97   : 0.035150000000000015\n",
      "Error-rate Day 98   : 0.05559999999999998\n",
      "Error-rate Day 99   : 0.04800000000000004\n",
      "Error-rate Day 100   : 0.06810000000000005\n",
      "Error-rate Day 101   : 0.0665\n",
      "Error-rate Day 102   : 0.05784999999999996\n",
      "Error-rate Day 103   : 0.03874999999999995\n",
      "Error-rate Day 104   : 0.019499999999999962\n",
      "Error-rate Day 105   : 0.03354999999999997\n",
      "Error-rate Day 106   : 0.06455\n",
      "Error-rate Day 107   : 0.03354999999999997\n",
      "Error-rate Day 108   : 0.03990000000000005\n",
      "Error-rate Day 109   : 0.024950000000000028\n",
      "Error-rate Day 110   : 0.03200000000000003\n",
      "Error-rate Day 111   : 0.03469999999999995\n",
      "Error-rate Day 112   : 0.03344999999999998\n",
      "Error-rate Day 113   : 0.03380000000000005\n",
      "Error-rate Day 114   : 0.036800000000000055\n",
      "Error-rate Day 115   : 0.03134999999999999\n",
      "Error-rate Day 116   : 0.042100000000000026\n",
      "Error-rate Day 117   : 0.03334999999999999\n",
      "Error-rate Day 118   : 0.0262\n",
      "Error-rate Day 119   : 0.0262\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#print(\"Error-rate Day {}   : {}\".format(0, train_and_evaluate(0, 1, clf, 1000)))\n",
    "\n",
    "for i in range(1, num_of_days):\n",
    "    Y_preds = clf.predict(X[i])\n",
    "    print(\"Error-rate Day {}   : {}\".format(i,1 - accuracy_score(Y[i], Y_preds)))\n",
    "    \n",
    "    \n",
    "# dieser ufunc error ist derselbe der mich schon gestern abend genervt hat.\n",
    "# erstmal ignorieren i guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309903ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
