{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a6e22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "data = scipy.io.loadmat('../../url.mat')\n",
    "#'../../data/url.mat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9fc2f1",
   "metadata": {},
   "source": [
    "**create list for labels and data, where one entry is the data for the day with this index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c361a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_of_days = 120\n",
    "X, Y = [], []\n",
    "\n",
    "for i in range(num_of_days):\n",
    "    day_data = data[\"Day\" + str(i)]\n",
    "    X.append(day_data[0][0][0])\n",
    "    Y.append(day_data[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4dae69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y)):\n",
    "    Y[i] = Y[i].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482f91d",
   "metadata": {},
   "source": [
    "**continous learn classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d324f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incremental learns classifier (must have partial_fit() function)\n",
    "# returns an array of cumulative error rates for each day\n",
    "def learn_incremental(clf, batch_size = 1000):\n",
    "    \n",
    "    #print(\"Batch size {}\".format(batch_size))\n",
    "    error_rates = []\n",
    "    num_of_days = 120\n",
    "    err = 0\n",
    "    \n",
    "    for curr_day in range(num_of_days): # looping through days\n",
    "    \n",
    "        if (curr_day != 45):\n",
    "            X_curr_day = X[curr_day]\n",
    "    \n",
    "            # split the data in slices of batch_size\n",
    "            batches_amount = int(X_curr_day.shape[0] / batch_size)\n",
    "            Y_curr_day = np.array_split(Y[curr_day], batches_amount)\n",
    "    \n",
    "            for j in range(batches_amount): # looping through individual urls\n",
    "                select_ind = np.arange(j * batch_size, (j+1) * batch_size)\n",
    "        \n",
    "                X_curr_url_batch, Y_curr_url_batch = X_curr_day[select_ind,:], Y_curr_day[j] \n",
    "        \n",
    "                if (j > 0):\n",
    "                    Y_preds = clf.predict(X_curr_url_batch)\n",
    "            \n",
    "                    for k in range(batch_size):\n",
    "                        if(Y_preds[k] != Y_curr_url_batch[k]):\n",
    "                            err = err + 1\n",
    "        \n",
    "                clf.partial_fit(X_curr_url_batch, Y_curr_url_batch, classes=list(range(2))) # Continous fitting of urls and label\n",
    "            \n",
    "            print(\"Log: Day {}: {}\".format(curr_day ,err / X_curr_day.shape[0]))\n",
    "            error_rates.append(err / X_curr_day.shape[0])\n",
    "            err = 0\n",
    "    return error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee050259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# takes a range of days (start until to)\n",
    "# fits the model with the data from the range until \"to\" itself\n",
    "# for day \"to\" for each url_batch the data is refitted (prevoius days data from range + all batches up to current)\n",
    "# and predicticed for the succesive batch of urls\n",
    "# returns the cumulative error rate for day \"to\"\n",
    "# batch_size determines the size of url_batches for which data is predicted and fitted on the \"to\" day\n",
    "def train_and_evaluate(start, to, clf, batch_size = 1):\n",
    "    \n",
    "    if (to == 45):\n",
    "        print(\"ERROR TO CALLED ON 45 WHICH CONTAINS FAULTY DATA\")\n",
    "        return\n",
    "    \n",
    "    prev_x = X[0][0,:] #random row for initialization purposes, spliced off later before classifying\n",
    "    \n",
    "    prev_y = []\n",
    "    for prev_day in range(start, to):\n",
    "        \n",
    "        if (prev_day != 45): # leave out day 45\n",
    "            prev_x = vstack((prev_x, X[prev_day])) # stack up all matrices to previous day\n",
    "            prev_y = np.concatenate((prev_y, Y[prev_day])) # stack up all labels to previous day\n",
    "        \n",
    "    # immediately splice off the first initial url used to initiate the matrix outside of the loop\n",
    "    url_indexes_without_initial = np.arange(1, prev_x.shape[0])\n",
    "    prev_x = prev_x.tocsr()[url_indexes_without_initial,:]\n",
    "    \n",
    "    # change X to row format for faster slicing row-wise.\n",
    "    curr_day_x = X[to].tocsr()\n",
    "    \n",
    "    # split the data in slices of batch_size\n",
    "    batches_amount = int(curr_day_x.shape[0] / batch_size)\n",
    "    curr_day_y = np.array_split(Y[to], batches_amount)\n",
    "    \n",
    "    err = 0\n",
    "    x_batches = X[0][0,:] #random row for initialization purposes, spliced off later before classifying\n",
    "    y_batches = []\n",
    "    for j in range(batches_amount): # looping through individual url-batches\n",
    "       \n",
    "        # Combine previous days data and all batches up until current\n",
    "        #print(\"parts:\")\n",
    "        #print(\"current batches: {}\".format(x_batches.shape))\n",
    "        #print(\"previous: {}\".format(prev_x.shape))\n",
    "        x_combined = vstack((prev_x, x_batches))\n",
    "        #y_combined = prev_y.extend(y_batches.ravel())\n",
    "        y_combined = np.append(prev_y, y_batches)\n",
    "        #print(\"unsliced comb:  {}\".format(x_combined.shape))\n",
    "        \n",
    "        if (j == 0):\n",
    "            # immediately splice off the trailing url used to initiate the matrix outside of the loop\n",
    "            url_indexes_without_trailing = np.arange(0, prev_x.shape[0])\n",
    "            x_combined = x_combined.tocsr()[url_indexes_without_trailing,:]\n",
    "            \n",
    "            \n",
    "        #print(\"sliced comb:  {}\".format(x_combined.shape))\n",
    "        #print(\"y-sliced comb:  {}\".format(len(y_combined)))\n",
    "        \n",
    "        \n",
    "        # Train for cumulated data excluding current batch\n",
    "        if (x_combined.shape[0] != 0):\n",
    "            clf.fit(x_combined, y_combined)\n",
    "    \n",
    "        # splice current batch off\n",
    "        select_ind = np.arange(j * batch_size, (j+1) * batch_size)\n",
    "        curr_x_batch, curr_y_batch = curr_day_x[select_ind,:], curr_day_y[j] \n",
    "        \n",
    "        # Add current batch to cumulated list of batches\n",
    "        x_batches = vstack((x_batches, curr_x_batch))\n",
    "        if (j == 0):\n",
    "            # immediately splice off the first initial url used to initiate the matrix outside of the loop\n",
    "            url_indexes_without_initial = np.arange(1, x_batches.shape[0])\n",
    "            x_batches = x_batches.tocsr()[url_indexes_without_initial,:]\n",
    "            \n",
    "        y_batches.extend(curr_y_batch)\n",
    "        \n",
    "        # Predict for current batch\n",
    "        if (x_combined.shape[0] != 0):\n",
    "            Y_preds = clf.predict(curr_x_batch)\n",
    "           \n",
    "            # Collect errors\n",
    "            # todo replace with accuracy score\n",
    "            for k in range(batch_size):\n",
    "                if(Y_preds[k] != curr_y_batch[k]):\n",
    "                    err = err + 1\n",
    "        \n",
    "    return err / curr_day_x.shape[0] # Return cumulative error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c688528a",
   "metadata": {},
   "source": [
    "### Batch-size and other global variables and imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dae7fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "batch_size = 4000\n",
    "train_set_size = 17 # Determines on data of how many days training is performed for SVM-multi and SVM-multi-once\n",
    "\n",
    "# Initialize error rates of the different classifiers\n",
    "error_rates_pa = None\n",
    "error_rates_svm_once = None\n",
    "error_rates_svm_daily = None\n",
    "error_rates_svm_multi_once = None\n",
    "error_rates_svm_multi = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe60b6",
   "metadata": {},
   "source": [
    "### SVM-once\n",
    "**Evaluate for all days**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a178617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error-rate Day 0   : 0.0211875\n",
      "Error-rate Day 1   : 0.027800000000000047\n",
      "Error-rate Day 2   : 0.023349999999999982\n",
      "Error-rate Day 3   : 0.023050000000000015\n",
      "Error-rate Day 4   : 0.025900000000000034\n",
      "Error-rate Day 5   : 0.02849999999999997\n",
      "Error-rate Day 6   : 0.03254999999999997\n",
      "Error-rate Day 7   : 0.03590000000000004\n",
      "Error-rate Day 8   : 0.036699999999999955\n",
      "Error-rate Day 9   : 0.039100000000000024\n",
      "Error-rate Day 10   : 0.036800000000000055\n",
      "Error-rate Day 11   : 0.03500000000000003\n",
      "Error-rate Day 12   : 0.029299999999999993\n",
      "Error-rate Day 13   : 0.023700000000000054\n",
      "Error-rate Day 14   : 0.032299999999999995\n",
      "Error-rate Day 15   : 0.027349999999999985\n",
      "Error-rate Day 16   : 0.029299999999999993\n",
      "Error-rate Day 17   : 0.02595000000000003\n",
      "Error-rate Day 18   : 0.02595000000000003\n",
      "Error-rate Day 19   : 0.026249999999999996\n",
      "Error-rate Day 20   : 0.03480000000000005\n",
      "Error-rate Day 21   : 0.041649999999999965\n",
      "Error-rate Day 22   : 0.04085000000000005\n",
      "Error-rate Day 23   : 0.03839999999999999\n",
      "Error-rate Day 24   : 0.04049999999999998\n",
      "Error-rate Day 25   : 0.036800000000000055\n",
      "Error-rate Day 26   : 0.032850000000000046\n",
      "Error-rate Day 27   : 0.03159999999999996\n",
      "Error-rate Day 28   : 0.030000000000000027\n",
      "Error-rate Day 29   : 0.029750000000000054\n",
      "Error-rate Day 30   : 0.038250000000000006\n",
      "Error-rate Day 31   : 0.039349999999999996\n",
      "Error-rate Day 32   : 0.03739999999999999\n",
      "Error-rate Day 33   : 0.03854999999999997\n",
      "Error-rate Day 34   : 0.042950000000000044\n",
      "Error-rate Day 35   : 0.049250000000000016\n",
      "Error-rate Day 36   : 0.042300000000000004\n",
      "Error-rate Day 37   : 0.0413\n",
      "Error-rate Day 38   : 0.05840000000000001\n",
      "Error-rate Day 39   : 0.06159999999999999\n",
      "Error-rate Day 40   : 0.04290000000000005\n",
      "Error-rate Day 41   : 0.03234999999999999\n",
      "Error-rate Day 42   : 0.038900000000000046\n",
      "Error-rate Day 43   : 0.04059999999999997\n",
      "Error-rate Day 44   : 0.02849999999999997\n",
      "Error-rate Day 45   : 0.023076923076923106\n",
      "Error-rate Day 46   : 0.033499999999999974\n",
      "Error-rate Day 47   : 0.03554999999999997\n",
      "Error-rate Day 48   : 0.06084999999999996\n",
      "Error-rate Day 49   : 0.05225000000000002\n",
      "Error-rate Day 50   : 0.047150000000000025\n",
      "Error-rate Day 51   : 0.040100000000000025\n",
      "Error-rate Day 52   : 0.037349999999999994\n",
      "Error-rate Day 53   : 0.042950000000000044\n",
      "Error-rate Day 54   : 0.03774999999999995\n",
      "Error-rate Day 55   : 0.029000000000000026\n",
      "Error-rate Day 56   : 0.03154999999999997\n",
      "Error-rate Day 57   : 0.02969999999999995\n",
      "Error-rate Day 58   : 0.03149999999999997\n",
      "Error-rate Day 59   : 0.03269999999999995\n",
      "Error-rate Day 60   : 0.03664999999999996\n",
      "Error-rate Day 61   : 0.04039999999999999\n",
      "Error-rate Day 62   : 0.05020000000000002\n",
      "Error-rate Day 63   : 0.047699999999999965\n",
      "Error-rate Day 64   : 0.03959999999999997\n",
      "Error-rate Day 65   : 0.04310000000000003\n",
      "Error-rate Day 66   : 0.03939999999999999\n",
      "Error-rate Day 67   : 0.04354999999999998\n",
      "Error-rate Day 68   : 0.04290000000000005\n",
      "Error-rate Day 69   : 0.03259999999999996\n",
      "Error-rate Day 70   : 0.03869999999999996\n",
      "Error-rate Day 71   : 0.03595000000000004\n",
      "Error-rate Day 72   : 0.03534999999999999\n",
      "Error-rate Day 73   : 0.03644999999999998\n",
      "Error-rate Day 74   : 0.0353\n",
      "Error-rate Day 75   : 0.03925000000000001\n",
      "Error-rate Day 76   : 0.04400000000000004\n",
      "Error-rate Day 77   : 0.03290000000000004\n",
      "Error-rate Day 78   : 0.041100000000000025\n",
      "Error-rate Day 79   : 0.03959999999999997\n",
      "Error-rate Day 80   : 0.03949999999999998\n",
      "Error-rate Day 81   : 0.034599999999999964\n",
      "Error-rate Day 82   : 0.028900000000000037\n",
      "Error-rate Day 83   : 0.029950000000000032\n",
      "Error-rate Day 84   : 0.028100000000000014\n",
      "Error-rate Day 85   : 0.03025\n",
      "Error-rate Day 86   : 0.030399999999999983\n",
      "Error-rate Day 87   : 0.03149999999999997\n",
      "Error-rate Day 88   : 0.03125\n",
      "Error-rate Day 89   : 0.028800000000000048\n",
      "Error-rate Day 90   : 0.02949999999999997\n",
      "Error-rate Day 91   : 0.02815000000000001\n",
      "Error-rate Day 92   : 0.03190000000000004\n",
      "Error-rate Day 93   : 0.03269999999999995\n",
      "Error-rate Day 94   : 0.03210000000000002\n",
      "Error-rate Day 95   : 0.019199999999999995\n",
      "Error-rate Day 96   : 0.030299999999999994\n",
      "Error-rate Day 97   : 0.040000000000000036\n",
      "Error-rate Day 98   : 0.040000000000000036\n",
      "Error-rate Day 99   : 0.041549999999999976\n",
      "Error-rate Day 100   : 0.04500000000000004\n",
      "Error-rate Day 101   : 0.04239999999999999\n",
      "Error-rate Day 102   : 0.043399999999999994\n",
      "Error-rate Day 103   : 0.03764999999999996\n",
      "Error-rate Day 104   : 0.029249999999999998\n",
      "Error-rate Day 105   : 0.029000000000000026\n",
      "Error-rate Day 106   : 0.02664999999999995\n",
      "Error-rate Day 107   : 0.026050000000000018\n",
      "Error-rate Day 108   : 0.04290000000000005\n",
      "Error-rate Day 109   : 0.023800000000000043\n",
      "Error-rate Day 110   : 0.03385000000000005\n",
      "Error-rate Day 111   : 0.04074999999999995\n",
      "Error-rate Day 112   : 0.03974999999999995\n",
      "Error-rate Day 113   : 0.039000000000000035\n",
      "Error-rate Day 114   : 0.04069999999999996\n",
      "Error-rate Day 115   : 0.03700000000000003\n",
      "Error-rate Day 116   : 0.04854999999999998\n",
      "Error-rate Day 117   : 0.04085000000000005\n",
      "Error-rate Day 118   : 0.030200000000000005\n",
      "Error-rate Day 119   : 0.03049999999999997\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(C=0.01)\n",
    "\n",
    "error_rates_svm_once = []\n",
    "rate = train_and_evaluate(0, 0, clf, batch_size)\n",
    "print(\"Error-rate Day {}   : {}\".format(0, rate))\n",
    "error_rates_svm_once.append(rate)\n",
    "\n",
    "for i in range(1, num_of_days):\n",
    "    Y_preds = clf.predict(X[i])\n",
    "    rate = 1 - accuracy_score(Y[i], Y_preds)\n",
    "    error_rates_svm_once.append(rate)\n",
    "    print(\"Error-rate Day {}   : {}\".format(i,rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9b257",
   "metadata": {},
   "source": [
    "### SVM-daily\n",
    "**Train on data of previous day and predict of successive day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5e4c94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error-rate Day 0   : 0.0211875\n",
      "Error-rate Day 2   : 0.021299999999999986\n",
      "Error-rate Day 3   : 0.02124999999999999\n",
      "Error-rate Day 4   : 0.023950000000000027\n",
      "Error-rate Day 5   : 0.023150000000000004\n",
      "Error-rate Day 6   : 0.018299999999999983\n",
      "Error-rate Day 7   : 0.02300000000000002\n",
      "Error-rate Day 8   : 0.022150000000000003\n",
      "Error-rate Day 9   : 0.027000000000000024\n",
      "Error-rate Day 10   : 0.02429999999999999\n",
      "Error-rate Day 11   : 0.023050000000000015\n",
      "Error-rate Day 12   : 0.023399999999999976\n",
      "Error-rate Day 13   : 0.01849999999999996\n",
      "Error-rate Day 14   : 0.026100000000000012\n",
      "Error-rate Day 15   : 0.020449999999999968\n",
      "Error-rate Day 16   : 0.02100000000000002\n",
      "Error-rate Day 17   : 0.020299999999999985\n",
      "Error-rate Day 18   : 0.021399999999999975\n",
      "Error-rate Day 19   : 0.020299999999999985\n",
      "Error-rate Day 20   : 0.02300000000000002\n",
      "Error-rate Day 21   : 0.029900000000000038\n",
      "Error-rate Day 22   : 0.02100000000000002\n",
      "Error-rate Day 23   : 0.02675000000000005\n",
      "Error-rate Day 24   : 0.03154999999999997\n",
      "Error-rate Day 25   : 0.028900000000000037\n",
      "Error-rate Day 26   : 0.030000000000000027\n",
      "Error-rate Day 27   : 0.03244999999999998\n",
      "Error-rate Day 28   : 0.02464999999999995\n",
      "Error-rate Day 29   : 0.027900000000000036\n",
      "Error-rate Day 30   : 0.03485000000000005\n",
      "Error-rate Day 31   : 0.03359999999999996\n",
      "Error-rate Day 32   : 0.028900000000000037\n",
      "Error-rate Day 33   : 0.028100000000000014\n",
      "Error-rate Day 34   : 0.030850000000000044\n",
      "Error-rate Day 35   : 0.25144999999999995\n",
      "Error-rate Day 36   : 0.03115000000000001\n",
      "Error-rate Day 37   : 0.0\n",
      "Error-rate Day 38   : 0.3558\n",
      "Error-rate Day 39   : 0.04149999999999998\n",
      "Error-rate Day 40   : 0.030950000000000033\n",
      "Error-rate Day 41   : 0.02410000000000001\n",
      "Error-rate Day 42   : 0.032749999999999946\n",
      "Error-rate Day 43   : 0.030750000000000055\n",
      "Error-rate Day 44   : 0.021599999999999953\n",
      "Error-rate Day 45   : 0.023076923076923106\n",
      "Error-rate Day 46   : 0.12104999999999999\n",
      "Error-rate Day 47   : 0.024449999999999972\n",
      "Error-rate Day 48   : 0.035050000000000026\n",
      "Error-rate Day 49   : 0.030399999999999983\n",
      "Error-rate Day 50   : 0.030200000000000005\n",
      "Error-rate Day 51   : 0.025499999999999967\n",
      "Error-rate Day 52   : 0.028100000000000014\n",
      "Error-rate Day 53   : 0.034050000000000025\n",
      "Error-rate Day 54   : 0.02564999999999995\n",
      "Error-rate Day 55   : 0.023249999999999993\n",
      "Error-rate Day 56   : 0.02475000000000005\n",
      "Error-rate Day 57   : 0.03125\n",
      "Error-rate Day 58   : 0.023950000000000027\n",
      "Error-rate Day 59   : 0.023900000000000032\n",
      "Error-rate Day 60   : 0.02529999999999999\n",
      "Error-rate Day 61   : 0.023150000000000004\n",
      "Error-rate Day 62   : 0.027249999999999996\n",
      "Error-rate Day 63   : 0.030299999999999994\n",
      "Error-rate Day 64   : 0.021599999999999953\n",
      "Error-rate Day 65   : 0.02795000000000003\n",
      "Error-rate Day 66   : 0.028649999999999953\n",
      "Error-rate Day 67   : 0.024449999999999972\n",
      "Error-rate Day 68   : 0.023150000000000004\n",
      "Error-rate Day 69   : 0.018399999999999972\n",
      "Error-rate Day 70   : 0.023850000000000038\n",
      "Error-rate Day 71   : 0.023700000000000054\n",
      "Error-rate Day 72   : 0.020050000000000012\n",
      "Error-rate Day 73   : 0.020100000000000007\n",
      "Error-rate Day 74   : 0.017349999999999977\n",
      "Error-rate Day 75   : 0.030549999999999966\n",
      "Error-rate Day 76   : 0.03249999999999997\n",
      "Error-rate Day 77   : 0.027150000000000007\n",
      "Error-rate Day 78   : 0.031299999999999994\n",
      "Error-rate Day 79   : 0.031749999999999945\n",
      "Error-rate Day 80   : 0.030000000000000027\n",
      "Error-rate Day 81   : 0.026549999999999963\n",
      "Error-rate Day 82   : 0.021199999999999997\n",
      "Error-rate Day 83   : 0.01805000000000001\n",
      "Error-rate Day 84   : 0.022399999999999975\n",
      "Error-rate Day 85   : 0.02575000000000005\n",
      "Error-rate Day 86   : 0.022649999999999948\n",
      "Error-rate Day 87   : 0.019000000000000017\n",
      "Error-rate Day 88   : 0.021549999999999958\n",
      "Error-rate Day 89   : 0.01770000000000005\n",
      "Error-rate Day 90   : 0.012750000000000039\n",
      "Error-rate Day 91   : 0.02200000000000002\n",
      "Error-rate Day 92   : 0.02190000000000003\n",
      "Error-rate Day 93   : 0.023249999999999993\n",
      "Error-rate Day 94   : 0.023900000000000032\n",
      "Error-rate Day 95   : 0.01100000000000001\n",
      "Error-rate Day 96   : 0.019950000000000023\n",
      "Error-rate Day 97   : 0.020950000000000024\n",
      "Error-rate Day 98   : 0.020850000000000035\n",
      "Error-rate Day 99   : 0.022599999999999953\n",
      "Error-rate Day 100   : 0.024449999999999972\n",
      "Error-rate Day 101   : 0.02485000000000004\n",
      "Error-rate Day 102   : 0.025599999999999956\n",
      "Error-rate Day 103   : 0.020449999999999968\n",
      "Error-rate Day 104   : 0.02344999999999997\n",
      "Error-rate Day 105   : 0.02554999999999996\n",
      "Error-rate Day 106   : 0.02024999999999999\n",
      "Error-rate Day 107   : 0.020199999999999996\n",
      "Error-rate Day 108   : 0.03649999999999998\n",
      "Error-rate Day 109   : 0.02354999999999996\n",
      "Error-rate Day 110   : 0.022499999999999964\n",
      "Error-rate Day 111   : 0.02080000000000004\n",
      "Error-rate Day 112   : 0.020750000000000046\n",
      "Error-rate Day 113   : 0.021100000000000008\n",
      "Error-rate Day 114   : 0.020299999999999985\n",
      "Error-rate Day 115   : 0.02375000000000005\n",
      "Error-rate Day 116   : 0.03585000000000005\n",
      "Error-rate Day 117   : 0.025900000000000034\n",
      "Error-rate Day 118   : 0.024800000000000044\n",
      "Error-rate Day 119   : 0.021599999999999953\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(C=0.01)\n",
    "\n",
    "error_rates_svm_daily = []\n",
    "error_rates_svm_daily.append(train_and_evaluate(0, 0, clf, batch_size))\n",
    "print(\"Error-rate Day {}   : {}\".format(0, error_rates_svm_daily[0]))\n",
    "for i in range(1, num_of_days - 1):\n",
    "    # i being the current day.\n",
    "    clf.fit(X[i], Y[i])\n",
    "    \n",
    "    # i + 1 being the next day on which the model is being tested on. \n",
    "    Y_preds = clf.predict(X[i + 1])\n",
    "    rate = 1 - accuracy_score(Y[i + 1], Y_preds)\n",
    "    error_rates_svm_daily.append(rate)\n",
    "    print(\"Error-rate Day {}   : {}\".format(i + 1, rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f0db3e",
   "metadata": {},
   "source": [
    "### SVM-multi-once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393457c",
   "metadata": {},
   "source": [
    "**Train once on data for days 0-16 (train_set_size) and (evaluate for those days)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed3c0efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error-rate Day 0   : 0.0211875\n",
      "Error-rate Day 1   : 0.02485\n",
      "Error-rate Day 2   : 0.0178\n",
      "Error-rate Day 3   : 0.0177\n",
      "Error-rate Day 4   : 0.01945\n",
      "Error-rate Day 5   : 0.0193\n",
      "Error-rate Day 6   : 0.017\n",
      "Error-rate Day 7   : 0.02075\n",
      "Error-rate Day 8   : 0.0178\n",
      "Error-rate Day 9   : 0.0206\n",
      "Error-rate Day 10   : 0.017\n",
      "Error-rate Day 11   : 0.0165\n",
      "Error-rate Day 12   : 0.01675\n",
      "Error-rate Day 13   : 0.013\n",
      "Error-rate Day 14   : 0.0181\n",
      "Error-rate Day 15   : 0.01385\n",
      "Error-rate Day 16   : 0.01355\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(C=0.01)\n",
    "error_rates_svm_multi_once =  []\n",
    "\n",
    "for i in range(train_set_size):\n",
    "    rate = train_and_evaluate(0, i, clf, batch_size)\n",
    "    error_rates_svm_multi_once.append(rate)\n",
    "    print(\"Error-rate Day {}   : {}\".format(i, rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86ed412",
   "metadata": {},
   "source": [
    "**Evaluate for the remaining days**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2701199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error-rate Day 17   : 0.01375000000000004\n",
      "Error-rate Day 18   : 0.014499999999999957\n",
      "Error-rate Day 19   : 0.013000000000000012\n",
      "Error-rate Day 20   : 0.014249999999999985\n",
      "Error-rate Day 21   : 0.019000000000000017\n",
      "Error-rate Day 22   : 0.01419999999999999\n",
      "Error-rate Day 23   : 0.018399999999999972\n",
      "Error-rate Day 24   : 0.021549999999999958\n",
      "Error-rate Day 25   : 0.021599999999999953\n",
      "Error-rate Day 26   : 0.01649999999999996\n",
      "Error-rate Day 27   : 0.017900000000000027\n",
      "Error-rate Day 28   : 0.017449999999999966\n",
      "Error-rate Day 29   : 0.02034999999999998\n",
      "Error-rate Day 30   : 0.02805000000000002\n",
      "Error-rate Day 31   : 0.026549999999999963\n",
      "Error-rate Day 32   : 0.02739999999999998\n",
      "Error-rate Day 33   : 0.02429999999999999\n",
      "Error-rate Day 34   : 0.015549999999999953\n",
      "Error-rate Day 35   : 0.026100000000000012\n",
      "Error-rate Day 36   : 0.015000000000000013\n",
      "Error-rate Day 37   : 0.014349999999999974\n",
      "Error-rate Day 38   : 0.031200000000000006\n",
      "Error-rate Day 39   : 0.03315000000000001\n",
      "Error-rate Day 40   : 0.0242\n",
      "Error-rate Day 41   : 0.01824999999999999\n",
      "Error-rate Day 42   : 0.02485000000000004\n",
      "Error-rate Day 43   : 0.021499999999999964\n",
      "Error-rate Day 44   : 0.015700000000000047\n",
      "Error-rate Day 45   : 0.01538461538461533\n",
      "Error-rate Day 46   : 0.016800000000000037\n",
      "Error-rate Day 47   : 0.018000000000000016\n",
      "Error-rate Day 48   : 0.024700000000000055\n",
      "Error-rate Day 49   : 0.027649999999999952\n",
      "Error-rate Day 50   : 0.02375000000000005\n",
      "Error-rate Day 51   : 0.020000000000000018\n",
      "Error-rate Day 52   : 0.020050000000000012\n",
      "Error-rate Day 53   : 0.02554999999999996\n",
      "Error-rate Day 54   : 0.01605000000000001\n",
      "Error-rate Day 55   : 0.016449999999999965\n",
      "Error-rate Day 56   : 0.01805000000000001\n",
      "Error-rate Day 57   : 0.015449999999999964\n",
      "Error-rate Day 58   : 0.018399999999999972\n",
      "Error-rate Day 59   : 0.01715\n",
      "Error-rate Day 60   : 0.018549999999999955\n",
      "Error-rate Day 61   : 0.019750000000000045\n",
      "Error-rate Day 62   : 0.019299999999999984\n",
      "Error-rate Day 63   : 0.024249999999999994\n",
      "Error-rate Day 64   : 0.019199999999999995\n",
      "Error-rate Day 65   : 0.021649999999999947\n",
      "Error-rate Day 66   : 0.017199999999999993\n",
      "Error-rate Day 67   : 0.01880000000000004\n",
      "Error-rate Day 68   : 0.016549999999999954\n",
      "Error-rate Day 69   : 0.014149999999999996\n",
      "Error-rate Day 70   : 0.017650000000000055\n",
      "Error-rate Day 71   : 0.016900000000000026\n",
      "Error-rate Day 72   : 0.016900000000000026\n",
      "Error-rate Day 73   : 0.017249999999999988\n",
      "Error-rate Day 74   : 0.01475000000000004\n",
      "Error-rate Day 75   : 0.019449999999999967\n",
      "Error-rate Day 76   : 0.02749999999999997\n",
      "Error-rate Day 77   : 0.017549999999999955\n",
      "Error-rate Day 78   : 0.028299999999999992\n",
      "Error-rate Day 79   : 0.031299999999999994\n",
      "Error-rate Day 80   : 0.027150000000000007\n",
      "Error-rate Day 81   : 0.020649999999999946\n",
      "Error-rate Day 82   : 0.023850000000000038\n",
      "Error-rate Day 83   : 0.022800000000000042\n",
      "Error-rate Day 84   : 0.02234999999999998\n",
      "Error-rate Day 85   : 0.031000000000000028\n",
      "Error-rate Day 86   : 0.02134999999999998\n",
      "Error-rate Day 87   : 0.02190000000000003\n",
      "Error-rate Day 88   : 0.021549999999999958\n",
      "Error-rate Day 89   : 0.030200000000000005\n",
      "Error-rate Day 90   : 0.025499999999999967\n",
      "Error-rate Day 91   : 0.02124999999999999\n",
      "Error-rate Day 92   : 0.02485000000000004\n",
      "Error-rate Day 93   : 0.02410000000000001\n",
      "Error-rate Day 94   : 0.02210000000000001\n",
      "Error-rate Day 95   : 0.009800000000000031\n",
      "Error-rate Day 96   : 0.016900000000000026\n",
      "Error-rate Day 97   : 0.017349999999999977\n",
      "Error-rate Day 98   : 0.03500000000000003\n",
      "Error-rate Day 99   : 0.026449999999999974\n",
      "Error-rate Day 100   : 0.023299999999999987\n",
      "Error-rate Day 101   : 0.022299999999999986\n",
      "Error-rate Day 102   : 0.023050000000000015\n",
      "Error-rate Day 103   : 0.016199999999999992\n",
      "Error-rate Day 104   : 0.013249999999999984\n",
      "Error-rate Day 105   : 0.01815\n",
      "Error-rate Day 106   : 0.01585000000000003\n",
      "Error-rate Day 107   : 0.014399999999999968\n",
      "Error-rate Day 108   : 0.02244999999999997\n",
      "Error-rate Day 109   : 0.01529999999999998\n",
      "Error-rate Day 110   : 0.013650000000000051\n",
      "Error-rate Day 111   : 0.014449999999999963\n",
      "Error-rate Day 112   : 0.015599999999999947\n",
      "Error-rate Day 113   : 0.016900000000000026\n",
      "Error-rate Day 114   : 0.01585000000000003\n",
      "Error-rate Day 115   : 0.017299999999999982\n",
      "Error-rate Day 116   : 0.02705000000000002\n",
      "Error-rate Day 117   : 0.02080000000000004\n",
      "Error-rate Day 118   : 0.01924999999999999\n",
      "Error-rate Day 119   : 0.017100000000000004\n"
     ]
    }
   ],
   "source": [
    "for i in range(train_set_size, num_of_days):\n",
    "    Y_preds = clf.predict(X[i])\n",
    "    rate = 1 - accuracy_score(Y[i], Y_preds)\n",
    "    error_rates_svm_multi_once.append(rate)\n",
    "    print(\"Error-rate Day {}   : {}\".format(i,rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19a3e3f",
   "metadata": {},
   "source": [
    "### SVM-multi\n",
    "**Train on data of previous 0-16 days (train_set_size) and predict of successive day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4c5432c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error-rate Day 0   : 0.0211875\n",
      "Error-rate Day 1   : 0.02485\n",
      "Error-rate Day 2   : 0.0178\n",
      "Error-rate Day 3   : 0.0177\n",
      "Error-rate Day 4   : 0.01945\n",
      "Error-rate Day 5   : 0.0193\n",
      "Error-rate Day 6   : 0.017\n",
      "Error-rate Day 7   : 0.02075\n",
      "Error-rate Day 8   : 0.0178\n",
      "Error-rate Day 9   : 0.0206\n",
      "Error-rate Day 10   : 0.017\n",
      "Error-rate Day 11   : 0.0165\n",
      "Error-rate Day 12   : 0.01675\n",
      "Error-rate Day 13   : 0.013\n",
      "Error-rate Day 14   : 0.0181\n",
      "Error-rate Day 15   : 0.01385\n",
      "Error-rate Day 16   : 0.01355\n",
      "Error-rate Day 17   : 0.01375\n",
      "Error-rate Day 18   : 0.0142\n",
      "Error-rate Day 19   : 0.0117\n",
      "Error-rate Day 20   : 0.01375\n",
      "Error-rate Day 21   : 0.01675\n",
      "Error-rate Day 22   : 0.0129\n",
      "Error-rate Day 23   : 0.0173\n",
      "Error-rate Day 24   : 0.0189\n",
      "Error-rate Day 25   : 0.02015\n",
      "Error-rate Day 26   : 0.01415\n",
      "Error-rate Day 27   : 0.01395\n",
      "Error-rate Day 28   : 0.01545\n",
      "Error-rate Day 29   : 0.0174\n",
      "Error-rate Day 30   : 0.02475\n",
      "Error-rate Day 31   : 0.02235\n",
      "Error-rate Day 32   : 0.01845\n",
      "Error-rate Day 33   : 0.01715\n",
      "Error-rate Day 34   : 0.0172\n",
      "Error-rate Day 35   : 0.0231\n",
      "Error-rate Day 36   : 0.01405\n",
      "Error-rate Day 37   : 0.01135\n",
      "Error-rate Day 38   : 0.02725\n",
      "Error-rate Day 39   : 0.03275\n",
      "Error-rate Day 40   : 0.0213\n",
      "Error-rate Day 41   : 0.01465\n",
      "Error-rate Day 42   : 0.022\n",
      "Error-rate Day 43   : 0.0189\n",
      "Error-rate Day 44   : 0.0129\n",
      "Error-rate Day 46   : 0.0145\n",
      "Error-rate Day 47   : 0.01545\n",
      "Error-rate Day 48   : 0.0207\n",
      "Error-rate Day 49   : 0.0204\n",
      "Error-rate Day 50   : 0.02045\n",
      "Error-rate Day 51   : 0.01635\n",
      "Error-rate Day 52   : 0.0174\n",
      "Error-rate Day 53   : 0.02105\n",
      "Error-rate Day 54   : 0.0136\n",
      "Error-rate Day 55   : 0.0158\n",
      "Error-rate Day 56   : 0.01625\n",
      "Error-rate Day 57   : 0.0128\n",
      "Error-rate Day 58   : 0.01365\n",
      "Error-rate Day 59   : 0.0142\n",
      "Error-rate Day 60   : 0.01355\n",
      "Error-rate Day 61   : 0.01375\n",
      "Error-rate Day 62   : 0.0147\n",
      "Error-rate Day 63   : 0.01805\n",
      "Error-rate Day 64   : 0.01415\n",
      "Error-rate Day 65   : 0.01785\n",
      "Error-rate Day 66   : 0.0132\n",
      "Error-rate Day 67   : 0.0156\n",
      "Error-rate Day 68   : 0.01335\n",
      "Error-rate Day 69   : 0.0114\n",
      "Error-rate Day 70   : 0.0154\n",
      "Error-rate Day 71   : 0.0166\n",
      "Error-rate Day 72   : 0.0147\n",
      "Error-rate Day 73   : 0.01485\n",
      "Error-rate Day 74   : 0.0129\n",
      "Error-rate Day 75   : 0.01655\n",
      "Error-rate Day 76   : 0.02475\n",
      "Error-rate Day 77   : 0.0132\n",
      "Error-rate Day 78   : 0.02065\n",
      "Error-rate Day 79   : 0.03085\n",
      "Error-rate Day 80   : 0.02095\n",
      "Error-rate Day 81   : 0.0191\n",
      "Error-rate Day 82   : 0.0132\n",
      "Error-rate Day 83   : 0.01235\n",
      "Error-rate Day 84   : 0.0126\n",
      "Error-rate Day 85   : 0.0157\n",
      "Error-rate Day 86   : 0.01245\n",
      "Error-rate Day 87   : 0.01005\n",
      "Error-rate Day 88   : 0.0126\n",
      "Error-rate Day 89   : 0.01065\n",
      "Error-rate Day 90   : 0.00895\n",
      "Error-rate Day 91   : 0.0104\n",
      "Error-rate Day 92   : 0.0126\n",
      "Error-rate Day 93   : 0.0138\n",
      "Error-rate Day 94   : 0.01105\n",
      "Error-rate Day 95   : 0.0062\n",
      "Error-rate Day 96   : 0.01245\n",
      "Error-rate Day 97   : 0.01565\n",
      "Error-rate Day 98   : 0.01535\n",
      "Error-rate Day 99   : 0.0155\n",
      "Error-rate Day 100   : 0.01795\n",
      "Error-rate Day 101   : 0.01745\n",
      "Error-rate Day 102   : 0.02125\n",
      "Error-rate Day 103   : 0.01385\n",
      "Error-rate Day 104   : 0.0096\n",
      "Error-rate Day 105   : 0.0156\n",
      "Error-rate Day 106   : 0.0107\n",
      "Error-rate Day 107   : 0.0102\n",
      "Error-rate Day 108   : 0.0155\n",
      "Error-rate Day 109   : 0.01165\n",
      "Error-rate Day 110   : 0.01035\n",
      "Error-rate Day 111   : 0.01155\n",
      "Error-rate Day 112   : 0.01375\n",
      "Error-rate Day 113   : 0.01395\n",
      "Error-rate Day 114   : 0.01335\n",
      "Error-rate Day 115   : 0.0146\n",
      "Error-rate Day 116   : 0.02175\n",
      "Error-rate Day 117   : 0.0135\n",
      "Error-rate Day 118   : 0.01245\n",
      "Error-rate Day 119   : 0.0123\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(C=0.01)\n",
    "\n",
    "error_rates_svm_multi = []\n",
    "for curr_day in range(0, num_of_days):\n",
    "    \n",
    "    if (curr_day != 45): # skip faulty data of day 45\n",
    "        lower_bound = max(0, ((curr_day - 1) - train_set_size))\n",
    "        upper_bound = curr_day\n",
    "        rate = train_and_evaluate(lower_bound, curr_day, clf, batch_size)\n",
    "        error_rates_svm_multi.append(rate)\n",
    "        print(\"Error-rate Day {}   : {}\".format(curr_day, rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed9da3",
   "metadata": {},
   "source": [
    "### Passive Aggressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3973eb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log: Day 0: 0.0295625\n",
      "Log: Day 1: 0.0264\n",
      "Log: Day 2: 0.022\n",
      "Log: Day 3: 0.0206\n",
      "Log: Day 4: 0.0222\n",
      "Log: Day 5: 0.0217\n",
      "Log: Day 6: 0.01735\n",
      "Log: Day 7: 0.0228\n",
      "Log: Day 8: 0.01905\n",
      "Log: Day 9: 0.0223\n",
      "Log: Day 10: 0.02165\n",
      "Log: Day 11: 0.0193\n",
      "Log: Day 12: 0.02005\n",
      "Log: Day 13: 0.01565\n",
      "Log: Day 14: 0.0182\n",
      "Log: Day 15: 0.01575\n",
      "Log: Day 16: 0.0162\n",
      "Log: Day 17: 0.0164\n",
      "Log: Day 18: 0.0166\n",
      "Log: Day 19: 0.0155\n",
      "Log: Day 20: 0.01755\n",
      "Log: Day 21: 0.0242\n",
      "Log: Day 22: 0.0164\n",
      "Log: Day 23: 0.0205\n",
      "Log: Day 24: 0.0234\n",
      "Log: Day 25: 0.02325\n",
      "Log: Day 26: 0.01595\n",
      "Log: Day 27: 0.0203\n",
      "Log: Day 28: 0.018\n",
      "Log: Day 29: 0.0221\n",
      "Log: Day 30: 0.0278\n",
      "Log: Day 31: 0.0225\n",
      "Log: Day 32: 0.02135\n",
      "Log: Day 33: 0.02265\n",
      "Log: Day 34: 0.00035\n",
      "Log: Day 35: 0.03155\n",
      "Log: Day 36: 0.0025\n",
      "Log: Day 37: 0.00075\n",
      "Log: Day 38: 0.0341\n",
      "Log: Day 39: 0.0344\n",
      "Log: Day 40: 0.02295\n",
      "Log: Day 41: 0.019\n",
      "Log: Day 42: 0.0225\n",
      "Log: Day 43: 0.0207\n",
      "Log: Day 44: 0.01415\n",
      "Log: Day 46: 0.0169\n",
      "Log: Day 47: 0.0174\n",
      "Log: Day 48: 0.02615\n",
      "Log: Day 49: 0.0227\n",
      "Log: Day 50: 0.02105\n",
      "Log: Day 51: 0.0179\n",
      "Log: Day 52: 0.01925\n",
      "Log: Day 53: 0.02215\n",
      "Log: Day 54: 0.0155\n",
      "Log: Day 55: 0.01485\n",
      "Log: Day 56: 0.01725\n",
      "Log: Day 57: 0.0148\n",
      "Log: Day 58: 0.0154\n",
      "Log: Day 59: 0.0161\n",
      "Log: Day 60: 0.016\n",
      "Log: Day 61: 0.0154\n",
      "Log: Day 62: 0.01595\n",
      "Log: Day 63: 0.02\n",
      "Log: Day 64: 0.0156\n",
      "Log: Day 65: 0.0188\n",
      "Log: Day 66: 0.015\n",
      "Log: Day 67: 0.0167\n",
      "Log: Day 68: 0.01465\n",
      "Log: Day 69: 0.0141\n",
      "Log: Day 70: 0.0159\n",
      "Log: Day 71: 0.0167\n",
      "Log: Day 72: 0.01565\n",
      "Log: Day 73: 0.01625\n",
      "Log: Day 74: 0.01415\n",
      "Log: Day 75: 0.01565\n",
      "Log: Day 76: 0.0194\n",
      "Log: Day 77: 0.01185\n",
      "Log: Day 78: 0.01625\n",
      "Log: Day 79: 0.01885\n",
      "Log: Day 80: 0.0183\n",
      "Log: Day 81: 0.0184\n",
      "Log: Day 82: 0.00985\n",
      "Log: Day 83: 0.0122\n",
      "Log: Day 84: 0.01395\n",
      "Log: Day 85: 0.0155\n",
      "Log: Day 86: 0.01315\n",
      "Log: Day 87: 0.0122\n",
      "Log: Day 88: 0.01335\n",
      "Log: Day 89: 0.00935\n",
      "Log: Day 90: 0.00665\n",
      "Log: Day 91: 0.0109\n",
      "Log: Day 92: 0.01445\n",
      "Log: Day 93: 0.01445\n",
      "Log: Day 94: 0.0114\n",
      "Log: Day 95: 0.0058\n",
      "Log: Day 96: 0.01205\n",
      "Log: Day 97: 0.0124\n",
      "Log: Day 98: 0.01285\n",
      "Log: Day 99: 0.0144\n",
      "Log: Day 100: 0.01515\n",
      "Log: Day 101: 0.01645\n",
      "Log: Day 102: 0.0178\n",
      "Log: Day 103: 0.0118\n",
      "Log: Day 104: 0.01155\n",
      "Log: Day 105: 0.01305\n",
      "Log: Day 106: 0.0102\n",
      "Log: Day 107: 0.0103\n",
      "Log: Day 108: 0.01855\n",
      "Log: Day 109: 0.0115\n",
      "Log: Day 110: 0.01285\n",
      "Log: Day 111: 0.01185\n",
      "Log: Day 112: 0.0137\n",
      "Log: Day 113: 0.01305\n",
      "Log: Day 114: 0.01335\n",
      "Log: Day 115: 0.0166\n",
      "Log: Day 116: 0.02065\n",
      "Log: Day 117: 0.0179\n",
      "Log: Day 118: 0.01625\n",
      "Log: Day 119: 0.01315\n",
      "Error-rate Day 0   : 0.0295625\n",
      "Error-rate Day 1   : 0.0264\n",
      "Error-rate Day 2   : 0.022\n",
      "Error-rate Day 3   : 0.0206\n",
      "Error-rate Day 4   : 0.0222\n",
      "Error-rate Day 5   : 0.0217\n",
      "Error-rate Day 6   : 0.01735\n",
      "Error-rate Day 7   : 0.0228\n",
      "Error-rate Day 8   : 0.01905\n",
      "Error-rate Day 9   : 0.0223\n",
      "Error-rate Day 10   : 0.02165\n",
      "Error-rate Day 11   : 0.0193\n",
      "Error-rate Day 12   : 0.02005\n",
      "Error-rate Day 13   : 0.01565\n",
      "Error-rate Day 14   : 0.0182\n",
      "Error-rate Day 15   : 0.01575\n",
      "Error-rate Day 16   : 0.0162\n",
      "Error-rate Day 17   : 0.0164\n",
      "Error-rate Day 18   : 0.0166\n",
      "Error-rate Day 19   : 0.0155\n",
      "Error-rate Day 20   : 0.01755\n",
      "Error-rate Day 21   : 0.0242\n",
      "Error-rate Day 22   : 0.0164\n",
      "Error-rate Day 23   : 0.0205\n",
      "Error-rate Day 24   : 0.0234\n",
      "Error-rate Day 25   : 0.02325\n",
      "Error-rate Day 26   : 0.01595\n",
      "Error-rate Day 27   : 0.0203\n",
      "Error-rate Day 28   : 0.018\n",
      "Error-rate Day 29   : 0.0221\n",
      "Error-rate Day 30   : 0.0278\n",
      "Error-rate Day 31   : 0.0225\n",
      "Error-rate Day 32   : 0.02135\n",
      "Error-rate Day 33   : 0.02265\n",
      "Error-rate Day 34   : 0.00035\n",
      "Error-rate Day 35   : 0.03155\n",
      "Error-rate Day 36   : 0.0025\n",
      "Error-rate Day 37   : 0.00075\n",
      "Error-rate Day 38   : 0.0341\n",
      "Error-rate Day 39   : 0.0344\n",
      "Error-rate Day 40   : 0.02295\n",
      "Error-rate Day 41   : 0.019\n",
      "Error-rate Day 42   : 0.0225\n",
      "Error-rate Day 43   : 0.0207\n",
      "Error-rate Day 44   : 0.01415\n",
      "Error-rate Day 45   : 0.0169\n",
      "Error-rate Day 46   : 0.0174\n",
      "Error-rate Day 47   : 0.02615\n",
      "Error-rate Day 48   : 0.0227\n",
      "Error-rate Day 49   : 0.02105\n",
      "Error-rate Day 50   : 0.0179\n",
      "Error-rate Day 51   : 0.01925\n",
      "Error-rate Day 52   : 0.02215\n",
      "Error-rate Day 53   : 0.0155\n",
      "Error-rate Day 54   : 0.01485\n",
      "Error-rate Day 55   : 0.01725\n",
      "Error-rate Day 56   : 0.0148\n",
      "Error-rate Day 57   : 0.0154\n",
      "Error-rate Day 58   : 0.0161\n",
      "Error-rate Day 59   : 0.016\n",
      "Error-rate Day 60   : 0.0154\n",
      "Error-rate Day 61   : 0.01595\n",
      "Error-rate Day 62   : 0.02\n",
      "Error-rate Day 63   : 0.0156\n",
      "Error-rate Day 64   : 0.0188\n",
      "Error-rate Day 65   : 0.015\n",
      "Error-rate Day 66   : 0.0167\n",
      "Error-rate Day 67   : 0.01465\n",
      "Error-rate Day 68   : 0.0141\n",
      "Error-rate Day 69   : 0.0159\n",
      "Error-rate Day 70   : 0.0167\n",
      "Error-rate Day 71   : 0.01565\n",
      "Error-rate Day 72   : 0.01625\n",
      "Error-rate Day 73   : 0.01415\n",
      "Error-rate Day 74   : 0.01565\n",
      "Error-rate Day 75   : 0.0194\n",
      "Error-rate Day 76   : 0.01185\n",
      "Error-rate Day 77   : 0.01625\n",
      "Error-rate Day 78   : 0.01885\n",
      "Error-rate Day 79   : 0.0183\n",
      "Error-rate Day 80   : 0.0184\n",
      "Error-rate Day 81   : 0.00985\n",
      "Error-rate Day 82   : 0.0122\n",
      "Error-rate Day 83   : 0.01395\n",
      "Error-rate Day 84   : 0.0155\n",
      "Error-rate Day 85   : 0.01315\n",
      "Error-rate Day 86   : 0.0122\n",
      "Error-rate Day 87   : 0.01335\n",
      "Error-rate Day 88   : 0.00935\n",
      "Error-rate Day 89   : 0.00665\n",
      "Error-rate Day 90   : 0.0109\n",
      "Error-rate Day 91   : 0.01445\n",
      "Error-rate Day 92   : 0.01445\n",
      "Error-rate Day 93   : 0.0114\n",
      "Error-rate Day 94   : 0.0058\n",
      "Error-rate Day 95   : 0.01205\n",
      "Error-rate Day 96   : 0.0124\n",
      "Error-rate Day 97   : 0.01285\n",
      "Error-rate Day 98   : 0.0144\n",
      "Error-rate Day 99   : 0.01515\n",
      "Error-rate Day 100   : 0.01645\n",
      "Error-rate Day 101   : 0.0178\n",
      "Error-rate Day 102   : 0.0118\n",
      "Error-rate Day 103   : 0.01155\n",
      "Error-rate Day 104   : 0.01305\n",
      "Error-rate Day 105   : 0.0102\n",
      "Error-rate Day 106   : 0.0103\n",
      "Error-rate Day 107   : 0.01855\n",
      "Error-rate Day 108   : 0.0115\n",
      "Error-rate Day 109   : 0.01285\n",
      "Error-rate Day 110   : 0.01185\n",
      "Error-rate Day 111   : 0.0137\n",
      "Error-rate Day 112   : 0.01305\n",
      "Error-rate Day 113   : 0.01335\n",
      "Error-rate Day 114   : 0.0166\n",
      "Error-rate Day 115   : 0.02065\n",
      "Error-rate Day 116   : 0.0179\n",
      "Error-rate Day 117   : 0.01625\n",
      "Error-rate Day 118   : 0.01315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "clf = PassiveAggressiveClassifier(C=0.001, random_state = 123)\n",
    "\n",
    "error_rates_pa = learn_incremental(clf, batch_size)\n",
    "\n",
    "cnt = 0\n",
    "for x in error_rates_pa:    \n",
    "    print(\"Error-rate Day {}   : {}\".format(cnt, x))\n",
    "    cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abd33c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calc_line(x, y):\n",
    "    \n",
    "    # create polynomial equation and calculate line\n",
    "    theta = np.polyfit(x, y, 8)\n",
    "    return theta[8] + theta[7] * pow(x, 1) + theta[6] * pow(x, 2) + theta[5] * pow(x, 3) + theta[4] * pow(x, 4) + theta[3] * pow(x, 5) + theta[2] * pow(x, 6) + theta[1] * pow(x, 7) + theta[0] * pow(x, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "83ca59e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot(y, color, scatter):\n",
    "    \n",
    "    # Set up the day_indexes with the missing 45th day in mind\n",
    "    X = np.arange(0, 120) \n",
    "    \n",
    "    Y = y\n",
    "    if (y.shape[0] < X.shape[0]):\n",
    "        #x = np.delete(x, 46)\n",
    "        Y = np.append(y, np.mean(y)) # add dummy point : this is ugly\n",
    "        \n",
    "    Y = Y * 100\n",
    "    print(Y)\n",
    "    Y = _calc_line(X, Y)\n",
    "    \n",
    "    plt.plot(X, Y, color)\n",
    "    \n",
    "    print(X)\n",
    "    print(Y)\n",
    "    if (scatter):\n",
    "        plt.scatter(X, Y, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b4cce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot8degree(error_rates_pa, error_rates_svm_once, error_rates_svm_daily,\n",
    "                error_rates_svm_multi_once, error_rates_svm_multi, batch_size, scatter = False):\n",
    "\n",
    "    \n",
    "    if (error_rates_pa is not None):\n",
    "        _plot(np.array(error_rates_pa), 'r', scatter)\n",
    "        \n",
    "    #if (error_rates_svm_once is not None):\n",
    "        #_plot(np.array(error_rates_svm_once), 'k', scatter)\n",
    "        \n",
    "   # if (error_rates_svm_daily is not None):\n",
    "        #_plot(np.array(error_rates_svm_daily), 'm', scatter)\n",
    "    \n",
    "    #if (error_rates_svm_multi_once is not None):\n",
    "        #_plot(np.array(error_rates_svm_multi_once), 'b', scatter)\n",
    "\n",
    "    #if (error_rates_svm_multi is not None):\n",
    "        #_plot(np.array(error_rates_svm_multi), 'g', scatter)\n",
    "        \n",
    "    plt.title('Experiment 1 with batch size {}'.format(batch_size))\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Cumulative error rate')\n",
    "    #plt.ylim([0,4])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4d910a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.95625    2.64       2.2        2.06       2.22       2.17\n",
      " 1.735      2.28       1.905      2.23       2.165      1.93\n",
      " 2.005      1.565      1.82       1.575      1.62       1.64\n",
      " 1.66       1.55       1.755      2.42       1.64       2.05\n",
      " 2.34       2.325      1.595      2.03       1.8        2.21\n",
      " 2.78       2.25       2.135      2.265      0.035      3.155\n",
      " 0.25       0.075      3.41       3.44       2.295      1.9\n",
      " 2.25       2.07       1.415      1.69       1.74       2.615\n",
      " 2.27       2.105      1.79       1.925      2.215      1.55\n",
      " 1.485      1.725      1.48       1.54       1.61       1.6\n",
      " 1.54       1.595      2.         1.56       1.88       1.5\n",
      " 1.67       1.465      1.41       1.59       1.67       1.565\n",
      " 1.625      1.415      1.565      1.94       1.185      1.625\n",
      " 1.885      1.83       1.84       0.985      1.22       1.395\n",
      " 1.55       1.315      1.22       1.335      0.935      0.665\n",
      " 1.09       1.445      1.445      1.14       0.58       1.205\n",
      " 1.24       1.285      1.44       1.515      1.645      1.78\n",
      " 1.18       1.155      1.305      1.02       1.03       1.855\n",
      " 1.15       1.285      1.185      1.37       1.305      1.335\n",
      " 1.66       2.065      1.79       1.625      1.315      1.69387605]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "[ 2.56040229  2.46573591  2.38009793  2.30295201  2.23377966  2.17207993\n",
      "  2.11736916  2.06918075  2.02706487  1.99058819  1.95933365  1.93290016\n",
      "  1.91090239  1.89297046  1.8787497   1.86790038  1.86009748  1.85503039\n",
      "  1.85240266  1.85193174  1.85334873  1.85639811  1.86083748  1.86643728\n",
      "  1.87298057  1.88026274  1.88809124  1.89628534  1.90467587  1.91310494\n",
      "  1.9214257   1.92950205  1.93720841  1.94442945  1.95105982  1.95700388\n",
      "  1.96217548  1.96649764  1.96990234  1.97233023  1.97373038  1.97406002\n",
      "  1.97328427  1.97137589  1.96831499  1.96408883  1.95869149  1.95212364\n",
      "  1.9443923   1.93551053  1.92549722  1.91437678  1.90217893  1.88893838\n",
      "  1.87469463  1.85949166  1.8433777   1.82640495  1.80862932  1.79011021\n",
      "  1.77091016  1.75109467  1.73073193  1.70989251  1.68864913  1.66707641\n",
      "  1.6452506   1.62324931  1.60115124  1.57903595  1.55698357  1.53507458\n",
      "  1.51338947  1.49200856 10.81939473 10.79886106 10.77886871 10.75949458\n",
      " 10.74081405 10.72290073 10.70582623 10.68965983 10.67446827 10.66031548\n",
      " 10.64726233 10.63536631 10.62468137 10.61525755 10.60714079 10.60037267\n",
      " 10.59499009 10.59102508 19.9368875  19.93583273 19.93625954 19.93817771\n",
      " 19.94159083 19.94649601 19.95288361 19.96073703 19.97003241 19.98073834\n",
      " 29.3411987  29.35460024 29.36927049 29.38514538 29.40215205 29.42020852\n",
      " 29.4392235  38.8074791  38.82809849 38.84934379 38.87108372 38.89317634\n",
      " 38.91546878 48.28618006 48.30836866 48.33023046 48.35156635 57.72054804]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter does not work\n",
    "#curve fucked at certain point\n",
    "\n",
    "plot8degree(error_rates_pa, error_rates_svm_once, error_rates_svm_daily,\n",
    "                error_rates_svm_multi_once, error_rates_svm_multi, batch_size, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e56879",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot8degree(error_rates_pa, error_rates_svm_once, error_rates_svm_daily,\n",
    "                error_rates_svm_multi_once, error_rates_svm_multi, batch_size, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ffb6213c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0295625, 0.0264, 0.022, 0.0206, 0.0222, 0.0217, 0.01735, 0.0228, 0.01905, 0.0223, 0.02165, 0.0193, 0.02005, 0.01565, 0.0182, 0.01575, 0.0162, 0.0164, 0.0166, 0.0155, 0.01755, 0.0242, 0.0164, 0.0205, 0.0234, 0.02325, 0.01595, 0.0203, 0.018, 0.0221, 0.0278, 0.0225, 0.02135, 0.02265, 0.00035, 0.03155, 0.0025, 0.00075, 0.0341, 0.0344, 0.02295, 0.019, 0.0225, 0.0207, 0.01415, 0.0169, 0.0174, 0.02615, 0.0227, 0.02105, 0.0179, 0.01925, 0.02215, 0.0155, 0.01485, 0.01725, 0.0148, 0.0154, 0.0161, 0.016, 0.0154, 0.01595, 0.02, 0.0156, 0.0188, 0.015, 0.0167, 0.01465, 0.0141, 0.0159, 0.0167, 0.01565, 0.01625, 0.01415, 0.01565, 0.0194, 0.01185, 0.01625, 0.01885, 0.0183, 0.0184, 0.00985, 0.0122, 0.01395, 0.0155, 0.01315, 0.0122, 0.01335, 0.00935, 0.00665, 0.0109, 0.01445, 0.01445, 0.0114, 0.0058, 0.01205, 0.0124, 0.01285, 0.0144, 0.01515, 0.01645, 0.0178, 0.0118, 0.01155, 0.01305, 0.0102, 0.0103, 0.01855, 0.0115, 0.01285, 0.01185, 0.0137, 0.01305, 0.01335, 0.0166, 0.02065, 0.0179, 0.01625, 0.01315]\n"
     ]
    }
   ],
   "source": [
    "print(error_rates_pa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8fcfe",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot8degree(error_rates, batch_size, scatter = False):\n",
    "    \n",
    "    # Set up the day_indexes with the missing 45th day in mind\n",
    "    x = np.arange(0, 120)\n",
    "    y = np.array(error_rates)\n",
    "    \n",
    "    if (y.shape[0] < x.shape[0]):\n",
    "        x = np.delete(x, 46)\n",
    "    y = y * 100\n",
    "\n",
    "    # create polynomial equation and calculate line\n",
    "    theta = np.polyfit(x, y, 8)\n",
    "    y_line = theta[8] + theta[7] * pow(x, 1) + theta[6] * pow(x, 2) + theta[5] * pow(x, 3) + theta[4] * pow(x, 4) + theta[3] * pow(x, 5) + theta[2] * pow(x, 6) + theta[1] * pow(x, 7) + theta[0] * pow(x, 8)\n",
    "\n",
    "    if (scatter):\n",
    "        plt.scatter(x, y)\n",
    "    \n",
    "    plt.plot(x, y_line, 'r')\n",
    "    plt.title('Experiment 1 with batch size {}'.format(batch_size))\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Cumulative error rate')\n",
    "    plt.ylim([0,4])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3873aa",
   "metadata": {},
   "source": [
    "#plot8degree(error_rates, batch_size, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
