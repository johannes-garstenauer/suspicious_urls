{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "774d9d7e",
   "metadata": {},
   "source": [
    "**Provide a path to the url.mat file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a6e22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "data = scipy.io.loadmat('../../data/url.mat')\n",
    "#'../../data/url.mat'\n",
    "#'../../url.mat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9fc2f1",
   "metadata": {},
   "source": [
    "**Create a list for labels and data, where one entry is the data for the day with the corresponding index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c361a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_of_days = 120\n",
    "X, Y = [], []\n",
    "\n",
    "for i in range(num_of_days):\n",
    "    day_data = data[\"Day\" + str(i)]\n",
    "    X.append(day_data[0][0][0])\n",
    "    Y.append(day_data[0][0][1])\n",
    "\n",
    "# Data cleanup (remove list within list)\n",
    "for i in range(len(Y)):\n",
    "    Y[i] = Y[i].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482f91d",
   "metadata": {},
   "source": [
    "**Function to do continous learning on a given classifier (clf) which must provide the partial_fit() function**\n",
    "\n",
    "*A batch size can be set, in order to train on a batch of URLs instead of individual URLs (to achieve classic online-learning, just set batch_size to 1*\n",
    "\n",
    "*Returns an array of cumulative error rates for each day*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d324f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_incremental(clf, batch_size = 1000):\n",
    "    \n",
    "    error_rates = []\n",
    "    num_of_days = 120\n",
    "    err = 0\n",
    "    \n",
    "    for curr_day in range(num_of_days): # Looping through days\n",
    "    \n",
    "        if (curr_day != 45): # Day 45 has faulty data and is therefor excluded\n",
    "            \n",
    "            X_curr_day = X[curr_day]\n",
    "            batches_amount = int(X_curr_day.shape[0] / batch_size)\n",
    "            Y_curr_day = np.array_split(Y[curr_day], batches_amount)\n",
    "    \n",
    "            for j in range(batches_amount): # looping through individual url-batches\n",
    "            \n",
    "                # Split the data in slices of the batch_size\n",
    "                select_ind = np.arange(j * batch_size, (j+1) * batch_size)\n",
    "                X_curr_url_batch, Y_curr_url_batch = X_curr_day[select_ind,:], Y_curr_day[j] \n",
    "        \n",
    "                if (j > 0):\n",
    "                    Y_preds = clf.predict(X_curr_url_batch)\n",
    "            \n",
    "                    for k in range(batch_size): # Compare given results to collected results and collect number of errors accordingly\n",
    "                        if(Y_preds[k] != Y_curr_url_batch[k]):\n",
    "                            err = err + 1\n",
    "        \n",
    "                # Continous fitting of urls and label\n",
    "                clf.partial_fit(X_curr_url_batch, Y_curr_url_batch, classes=list(range(2)))            \n",
    "            print(\"Log: Day {}: {}\".format(curr_day ,err / X_curr_day.shape[0]))\n",
    "            error_rates.append(err / X_curr_day.shape[0])\n",
    "            err = 0\n",
    "    return error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e98a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# takes a range of days (start until to)\n",
    "# fits the model with the data from the range until \"to\" itself\n",
    "# for day \"to\" for each url_batch the data is refitted (prevoius days data from range + all batches up to current)\n",
    "# and predicticed for the succesive batch of urls\n",
    "# returns the cumulative error rate for day \"to\"\n",
    "# batch_size determines the size of url_batches for which data is predicted and fitted on the \"to\" day\n",
    "def train_and_evaluate_day(start, to, clf):\n",
    "    \n",
    "    if (to == 45):\n",
    "        print(\"ERROR CALLED ON 45 WHICH CONTAINS FAULTY DATA\")\n",
    "        return\n",
    "    \n",
    "    prev_x = X[0][0,:] #random row for initialization purposes, spliced off later before training\n",
    "    prev_y = []\n",
    "    for prev_day in range(start, to):\n",
    "        \n",
    "        if (prev_day != 45): # leave out day 45\n",
    "            prev_x = vstack((prev_x, X[prev_day])) # stack up all matrices to previous day\n",
    "            prev_y = np.concatenate((prev_y, Y[prev_day])) # stack up all labels to previous day\n",
    "        \n",
    "    # immediately splice off the first initial url used to initiate the matrix outside of the loop\n",
    "    url_indexes_without_initial = np.arange(1, prev_x.shape[0])\n",
    "    prev_x = prev_x.tocsr()[url_indexes_without_initial,:]\n",
    "    \n",
    "    # change X to row format for faster slicing row-wise.\n",
    "    curr_day_x = X[to].tocsr()\n",
    "    curr_day_y = Y[to] # new\n",
    "    \n",
    "    clf.fit(prev_x, prev_y) #new\n",
    "    \n",
    "    Y_preds = clf.predict(curr_day_x)\n",
    "    \n",
    "    # Return cumulative error rate\n",
    "    return 1 - accuracy_score(curr_day_y, Y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee050259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# takes a range of days (start until to)\n",
    "# fits the model with the data from the range until \"to\" itself\n",
    "# for day \"to\" for each url_batch the data is refitted (prevoius days data from range + all batches up to current)\n",
    "# and predicticed for the succesive batch of urls\n",
    "# returns the cumulative error rate for day \"to\"\n",
    "# batch_size determines the size of url_batches for which data is predicted and fitted on the \"to\" day\n",
    "def train_and_evaluate(start, to, clf, batch_size = 1):\n",
    "    \n",
    "    if (to == 45):\n",
    "        print(\"ERROR CALLED ON 45 WHICH CONTAINS FAULTY DATA\")\n",
    "        return\n",
    "    \n",
    "    prev_x = X[0][0,:] #random row for initialization purposes, spliced off later before classifying\n",
    "    \n",
    "    prev_y = []\n",
    "    for prev_day in range(start, to):\n",
    "        \n",
    "        if (prev_day != 45): # leave out day 45\n",
    "            prev_x = vstack((prev_x, X[prev_day])) # stack up all matrices to previous day\n",
    "            prev_y = np.concatenate((prev_y, Y[prev_day])) # stack up all labels to previous day\n",
    "        \n",
    "    # immediately splice off the first initial url used to initiate the matrix outside of the loop\n",
    "    url_indexes_without_initial = np.arange(1, prev_x.shape[0])\n",
    "    prev_x = prev_x.tocsr()[url_indexes_without_initial,:]\n",
    "    \n",
    "    # change X to row format for faster slicing row-wise.\n",
    "    curr_day_x = X[to].tocsr()\n",
    "    \n",
    "    # split the data in slices of batch_size\n",
    "    batches_amount = int(curr_day_x.shape[0] / batch_size)\n",
    "    curr_day_y = np.array_split(Y[to], batches_amount)\n",
    "    \n",
    "    err = 0\n",
    "    x_batches = X[0][0,:] #random row for initialization purposes, spliced off later before classifying\n",
    "    y_batches = []\n",
    "    for j in range(batches_amount): # looping through individual url-batches\n",
    "       \n",
    "        # Combine previous days data and all batches up until current\n",
    "        #print(\"parts:\")\n",
    "        #print(\"current batches: {}\".format(x_batches.shape))\n",
    "        #print(\"previous: {}\".format(prev_x.shape))\n",
    "        x_combined = vstack((prev_x, x_batches))\n",
    "        #y_combined = prev_y.extend(y_batches.ravel())\n",
    "        y_combined = np.append(prev_y, y_batches)\n",
    "        #print(\"unsliced comb:  {}\".format(x_combined.shape))\n",
    "        \n",
    "        if (j == 0):\n",
    "            # immediately splice off the trailing url used to initiate the matrix outside of the loop\n",
    "            url_indexes_without_trailing = np.arange(0, prev_x.shape[0])\n",
    "            x_combined = x_combined.tocsr()[url_indexes_without_trailing,:]\n",
    "            \n",
    "            \n",
    "        #print(\"sliced comb:  {}\".format(x_combined.shape))\n",
    "        #print(\"y-sliced comb:  {}\".format(len(y_combined)))\n",
    "        \n",
    "        \n",
    "        # Train for cumulated data excluding current batch\n",
    "        if (x_combined.shape[0] != 0):\n",
    "            clf.fit(x_combined, y_combined)\n",
    "    \n",
    "        # splice current batch off\n",
    "        select_ind = np.arange(j * batch_size, (j+1) * batch_size)\n",
    "        curr_x_batch, curr_y_batch = curr_day_x[select_ind,:], curr_day_y[j] \n",
    "        \n",
    "        # Add current batch to cumulated list of batches\n",
    "        x_batches = vstack((x_batches, curr_x_batch))\n",
    "        if (j == 0):\n",
    "            # immediately splice off the first initial url used to initiate the matrix outside of the loop\n",
    "            url_indexes_without_initial = np.arange(1, x_batches.shape[0])\n",
    "            x_batches = x_batches.tocsr()[url_indexes_without_initial,:]\n",
    "            \n",
    "        y_batches.extend(curr_y_batch)\n",
    "        \n",
    "        # Predict for current batch\n",
    "        if (x_combined.shape[0] != 0):\n",
    "            Y_preds = clf.predict(curr_x_batch)\n",
    "           \n",
    "            # Collect errors\n",
    "            # todo replace with accuracy score\n",
    "            for k in range(batch_size):\n",
    "                if(Y_preds[k] != curr_y_batch[k]):\n",
    "                    err = err + 1\n",
    "        \n",
    "    return err / curr_day_x.shape[0] # Return cumulative error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c688528a",
   "metadata": {},
   "source": [
    "### Batch-size and other global variables and imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dae7fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 1\n",
    "train_set_size = 17 # Determines on data of how many days training is performed for SVM-multi and SVM-multi-once\n",
    "\n",
    "# Initialize error rates of the different classifiers\n",
    "error_rates_pa = None\n",
    "error_rates_svm_once = None\n",
    "error_rates_svm_daily = None\n",
    "error_rates_svm_multi_once = None\n",
    "error_rates_svm_multi = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe60b6",
   "metadata": {},
   "source": [
    "### SVM-once\n",
    "**Evaluate for all days**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a178617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error-rate Day 1   : 0.02705000000000002\n",
      "Error-rate Day 2   : 0.021950000000000025\n",
      "Error-rate Day 3   : 0.02210000000000001\n",
      "Error-rate Day 4   : 0.02475000000000005\n",
      "Error-rate Day 5   : 0.027100000000000013\n",
      "Error-rate Day 6   : 0.03015000000000001\n",
      "Error-rate Day 7   : 0.03444999999999998\n",
      "Error-rate Day 8   : 0.03344999999999998\n",
      "Error-rate Day 9   : 0.03705000000000003\n",
      "Error-rate Day 10   : 0.03385000000000005\n",
      "Error-rate Day 11   : 0.03259999999999996\n",
      "Error-rate Day 12   : 0.027599999999999958\n",
      "Error-rate Day 13   : 0.022150000000000003\n",
      "Error-rate Day 14   : 0.030100000000000016\n",
      "Error-rate Day 15   : 0.02664999999999995\n",
      "Error-rate Day 16   : 0.029299999999999993\n",
      "Error-rate Day 17   : 0.025000000000000022\n",
      "Error-rate Day 18   : 0.025000000000000022\n",
      "Error-rate Day 19   : 0.024900000000000033\n",
      "Error-rate Day 20   : 0.03180000000000005\n",
      "Error-rate Day 21   : 0.03925000000000001\n",
      "Error-rate Day 22   : 0.03854999999999997\n",
      "Error-rate Day 23   : 0.03634999999999999\n",
      "Error-rate Day 24   : 0.037699999999999956\n",
      "Error-rate Day 25   : 0.03654999999999997\n",
      "Error-rate Day 26   : 0.03025\n",
      "Error-rate Day 27   : 0.030850000000000044\n",
      "Error-rate Day 28   : 0.028750000000000053\n",
      "Error-rate Day 29   : 0.029200000000000004\n",
      "Error-rate Day 30   : 0.03749999999999998\n",
      "Error-rate Day 31   : 0.03885000000000005\n",
      "Error-rate Day 32   : 0.03649999999999998\n",
      "Error-rate Day 33   : 0.03705000000000003\n",
      "Error-rate Day 34   : 0.039000000000000035\n",
      "Error-rate Day 35   : 0.04654999999999998\n",
      "Error-rate Day 36   : 0.03854999999999997\n",
      "Error-rate Day 37   : 0.03710000000000002\n",
      "Error-rate Day 38   : 0.05664999999999998\n",
      "Error-rate Day 39   : 0.05954999999999999\n",
      "Error-rate Day 40   : 0.04039999999999999\n",
      "Error-rate Day 41   : 0.031100000000000017\n",
      "Error-rate Day 42   : 0.038900000000000046\n",
      "Error-rate Day 43   : 0.03785000000000005\n",
      "Error-rate Day 44   : 0.02805000000000002\n",
      "Error-rate Day 45   : 0.023076923076923106\n",
      "Error-rate Day 46   : 0.03300000000000003\n",
      "Error-rate Day 47   : 0.03554999999999997\n",
      "Error-rate Day 48   : 0.05905000000000005\n",
      "Error-rate Day 49   : 0.05195000000000005\n",
      "Error-rate Day 50   : 0.04544999999999999\n",
      "Error-rate Day 51   : 0.03849999999999998\n",
      "Error-rate Day 52   : 0.03544999999999998\n",
      "Error-rate Day 53   : 0.041749999999999954\n",
      "Error-rate Day 54   : 0.0363\n",
      "Error-rate Day 55   : 0.028449999999999975\n",
      "Error-rate Day 56   : 0.030299999999999994\n",
      "Error-rate Day 57   : 0.028699999999999948\n",
      "Error-rate Day 58   : 0.030649999999999955\n",
      "Error-rate Day 59   : 0.031299999999999994\n",
      "Error-rate Day 60   : 0.03495000000000004\n",
      "Error-rate Day 61   : 0.03874999999999995\n",
      "Error-rate Day 62   : 0.04754999999999998\n",
      "Error-rate Day 63   : 0.04530000000000001\n",
      "Error-rate Day 64   : 0.03664999999999996\n",
      "Error-rate Day 65   : 0.04074999999999995\n",
      "Error-rate Day 66   : 0.03644999999999998\n",
      "Error-rate Day 67   : 0.04035\n",
      "Error-rate Day 68   : 0.040549999999999975\n",
      "Error-rate Day 69   : 0.030100000000000016\n",
      "Error-rate Day 70   : 0.03600000000000003\n",
      "Error-rate Day 71   : 0.03385000000000005\n",
      "Error-rate Day 72   : 0.03234999999999999\n",
      "Error-rate Day 73   : 0.03369999999999995\n",
      "Error-rate Day 74   : 0.032399999999999984\n",
      "Error-rate Day 75   : 0.037900000000000045\n",
      "Error-rate Day 76   : 0.04190000000000005\n",
      "Error-rate Day 77   : 0.031050000000000022\n",
      "Error-rate Day 78   : 0.040200000000000014\n",
      "Error-rate Day 79   : 0.037799999999999945\n",
      "Error-rate Day 80   : 0.038449999999999984\n",
      "Error-rate Day 81   : 0.03359999999999996\n",
      "Error-rate Day 82   : 0.029000000000000026\n",
      "Error-rate Day 83   : 0.029349999999999987\n",
      "Error-rate Day 84   : 0.02739999999999998\n",
      "Error-rate Day 85   : 0.031850000000000045\n",
      "Error-rate Day 86   : 0.02949999999999997\n",
      "Error-rate Day 87   : 0.031299999999999994\n",
      "Error-rate Day 88   : 0.03090000000000004\n",
      "Error-rate Day 89   : 0.03090000000000004\n",
      "Error-rate Day 90   : 0.029900000000000038\n",
      "Error-rate Day 91   : 0.028100000000000014\n",
      "Error-rate Day 92   : 0.03280000000000005\n",
      "Error-rate Day 93   : 0.03249999999999997\n",
      "Error-rate Day 94   : 0.03115000000000001\n",
      "Error-rate Day 95   : 0.01795000000000002\n",
      "Error-rate Day 96   : 0.029200000000000004\n",
      "Error-rate Day 97   : 0.03649999999999998\n",
      "Error-rate Day 98   : 0.03859999999999997\n",
      "Error-rate Day 99   : 0.03920000000000001\n",
      "Error-rate Day 100   : 0.04349999999999998\n",
      "Error-rate Day 101   : 0.040200000000000014\n",
      "Error-rate Day 102   : 0.04115000000000002\n",
      "Error-rate Day 103   : 0.03534999999999999\n",
      "Error-rate Day 104   : 0.0232\n",
      "Error-rate Day 105   : 0.026900000000000035\n",
      "Error-rate Day 106   : 0.02575000000000005\n",
      "Error-rate Day 107   : 0.024499999999999966\n",
      "Error-rate Day 108   : 0.041850000000000054\n",
      "Error-rate Day 109   : 0.023900000000000032\n",
      "Error-rate Day 110   : 0.03254999999999997\n",
      "Error-rate Day 111   : 0.03749999999999998\n",
      "Error-rate Day 112   : 0.03600000000000003\n",
      "Error-rate Day 113   : 0.03710000000000002\n",
      "Error-rate Day 114   : 0.03820000000000001\n",
      "Error-rate Day 115   : 0.035050000000000026\n",
      "Error-rate Day 116   : 0.04579999999999995\n",
      "Error-rate Day 117   : 0.038449999999999984\n",
      "Error-rate Day 118   : 0.028750000000000053\n",
      "Error-rate Day 119   : 0.029249999999999998\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(C=0.01)\n",
    "\n",
    "error_rates_svm_once = []\n",
    "#rate = train_and_evaluate(0, 0, clf, batch_size)\n",
    "#print(\"Error-rate Day {}   : {}\".format(0, rate))\n",
    "#error_rates_svm_once.append(rate)\n",
    "clf.fit(X[0], Y[0])\n",
    "for i in range(1, num_of_days):\n",
    "    Y_preds = clf.predict(X[i])\n",
    "    rate = 1 - accuracy_score(Y[i], Y_preds)\n",
    "    error_rates_svm_once.append(rate)\n",
    "    print(\"Error-rate Day {}   : {}\".format(i,rate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9b257",
   "metadata": {},
   "source": [
    "### SVM-daily\n",
    "**Train on data of previous day and predict of successive day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e4c94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error-rate Day 1   : 0.02705000000000002\n",
      "Error-rate Day 2   : 0.021299999999999986\n",
      "Error-rate Day 3   : 0.02124999999999999\n",
      "Error-rate Day 4   : 0.023950000000000027\n",
      "Error-rate Day 5   : 0.023150000000000004\n",
      "Error-rate Day 6   : 0.018299999999999983\n",
      "Error-rate Day 7   : 0.02300000000000002\n",
      "Error-rate Day 8   : 0.022150000000000003\n",
      "Error-rate Day 9   : 0.027000000000000024\n",
      "Error-rate Day 10   : 0.02429999999999999\n",
      "Error-rate Day 11   : 0.023050000000000015\n",
      "Error-rate Day 12   : 0.023399999999999976\n",
      "Error-rate Day 13   : 0.01849999999999996\n",
      "Error-rate Day 14   : 0.026100000000000012\n",
      "Error-rate Day 15   : 0.020449999999999968\n",
      "Error-rate Day 16   : 0.02100000000000002\n",
      "Error-rate Day 17   : 0.020299999999999985\n",
      "Error-rate Day 18   : 0.021399999999999975\n",
      "Error-rate Day 19   : 0.020299999999999985\n",
      "Error-rate Day 20   : 0.02300000000000002\n",
      "Error-rate Day 21   : 0.029900000000000038\n",
      "Error-rate Day 22   : 0.02100000000000002\n",
      "Error-rate Day 23   : 0.02675000000000005\n",
      "Error-rate Day 24   : 0.03154999999999997\n",
      "Error-rate Day 25   : 0.028900000000000037\n",
      "Error-rate Day 26   : 0.030000000000000027\n",
      "Error-rate Day 27   : 0.03244999999999998\n",
      "Error-rate Day 28   : 0.02464999999999995\n",
      "Error-rate Day 29   : 0.027900000000000036\n",
      "Error-rate Day 30   : 0.03485000000000005\n",
      "Error-rate Day 31   : 0.03359999999999996\n",
      "Error-rate Day 32   : 0.028900000000000037\n",
      "Error-rate Day 33   : 0.028100000000000014\n",
      "Error-rate Day 34   : 0.030850000000000044\n",
      "Error-rate Day 35   : 0.25144999999999995\n",
      "Error-rate Day 36   : 0.03115000000000001\n",
      "Error-rate Day 37   : 0.0\n",
      "Error-rate Day 38   : 0.3558\n",
      "Error-rate Day 39   : 0.04149999999999998\n",
      "Error-rate Day 40   : 0.030950000000000033\n",
      "Error-rate Day 41   : 0.02410000000000001\n",
      "Error-rate Day 42   : 0.032749999999999946\n",
      "Error-rate Day 43   : 0.030750000000000055\n",
      "Error-rate Day 44   : 0.021599999999999953\n",
      "Error-rate Day 45   : 0.023076923076923106\n",
      "Error-rate Day 46   : 0.12104999999999999\n",
      "Error-rate Day 47   : 0.024449999999999972\n",
      "Error-rate Day 48   : 0.035050000000000026\n",
      "Error-rate Day 49   : 0.030399999999999983\n",
      "Error-rate Day 50   : 0.030200000000000005\n",
      "Error-rate Day 51   : 0.025499999999999967\n",
      "Error-rate Day 52   : 0.028100000000000014\n",
      "Error-rate Day 53   : 0.034050000000000025\n",
      "Error-rate Day 54   : 0.02564999999999995\n",
      "Error-rate Day 55   : 0.023249999999999993\n",
      "Error-rate Day 56   : 0.02475000000000005\n",
      "Error-rate Day 57   : 0.03125\n",
      "Error-rate Day 58   : 0.023950000000000027\n",
      "Error-rate Day 59   : 0.023900000000000032\n",
      "Error-rate Day 60   : 0.02529999999999999\n",
      "Error-rate Day 61   : 0.023150000000000004\n",
      "Error-rate Day 62   : 0.027249999999999996\n",
      "Error-rate Day 63   : 0.030299999999999994\n",
      "Error-rate Day 64   : 0.021599999999999953\n",
      "Error-rate Day 65   : 0.02795000000000003\n",
      "Error-rate Day 66   : 0.028649999999999953\n",
      "Error-rate Day 67   : 0.024449999999999972\n",
      "Error-rate Day 68   : 0.023150000000000004\n",
      "Error-rate Day 69   : 0.018399999999999972\n",
      "Error-rate Day 70   : 0.023850000000000038\n",
      "Error-rate Day 71   : 0.023700000000000054\n",
      "Error-rate Day 72   : 0.020050000000000012\n",
      "Error-rate Day 73   : 0.020100000000000007\n",
      "Error-rate Day 74   : 0.017349999999999977\n",
      "Error-rate Day 75   : 0.030549999999999966\n",
      "Error-rate Day 76   : 0.03249999999999997\n",
      "Error-rate Day 77   : 0.027150000000000007\n",
      "Error-rate Day 78   : 0.031299999999999994\n",
      "Error-rate Day 79   : 0.031749999999999945\n",
      "Error-rate Day 80   : 0.030000000000000027\n",
      "Error-rate Day 81   : 0.026549999999999963\n",
      "Error-rate Day 82   : 0.021199999999999997\n",
      "Error-rate Day 83   : 0.01805000000000001\n",
      "Error-rate Day 84   : 0.022399999999999975\n",
      "Error-rate Day 85   : 0.02575000000000005\n",
      "Error-rate Day 86   : 0.022649999999999948\n",
      "Error-rate Day 87   : 0.019000000000000017\n",
      "Error-rate Day 88   : 0.021549999999999958\n",
      "Error-rate Day 89   : 0.01770000000000005\n",
      "Error-rate Day 90   : 0.012750000000000039\n",
      "Error-rate Day 91   : 0.02200000000000002\n",
      "Error-rate Day 92   : 0.02190000000000003\n",
      "Error-rate Day 93   : 0.023249999999999993\n",
      "Error-rate Day 94   : 0.023900000000000032\n",
      "Error-rate Day 95   : 0.01100000000000001\n",
      "Error-rate Day 96   : 0.019950000000000023\n",
      "Error-rate Day 97   : 0.020950000000000024\n",
      "Error-rate Day 98   : 0.02080000000000004\n",
      "Error-rate Day 99   : 0.022599999999999953\n",
      "Error-rate Day 100   : 0.024449999999999972\n",
      "Error-rate Day 101   : 0.02485000000000004\n",
      "Error-rate Day 102   : 0.025599999999999956\n",
      "Error-rate Day 103   : 0.020449999999999968\n",
      "Error-rate Day 104   : 0.02344999999999997\n",
      "Error-rate Day 105   : 0.02554999999999996\n",
      "Error-rate Day 106   : 0.02024999999999999\n",
      "Error-rate Day 107   : 0.020199999999999996\n",
      "Error-rate Day 108   : 0.03649999999999998\n",
      "Error-rate Day 109   : 0.02354999999999996\n",
      "Error-rate Day 110   : 0.022499999999999964\n",
      "Error-rate Day 111   : 0.02080000000000004\n",
      "Error-rate Day 112   : 0.020750000000000046\n",
      "Error-rate Day 113   : 0.021100000000000008\n",
      "Error-rate Day 114   : 0.020299999999999985\n",
      "Error-rate Day 115   : 0.02375000000000005\n",
      "Error-rate Day 116   : 0.03585000000000005\n",
      "Error-rate Day 117   : 0.025900000000000034\n",
      "Error-rate Day 118   : 0.024800000000000044\n",
      "Error-rate Day 119   : 0.021599999999999953\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(C=0.01)\n",
    "\n",
    "error_rates_svm_daily = []\n",
    "#error_rates_svm_daily.append(train_and_evaluate(0, 0, clf, batch_size))\n",
    "#print(\"Error-rate Day {}   : {}\".format(0, error_rates_svm_daily[0]))\n",
    "for i in range(0, num_of_days - 1):\n",
    "    # i being the current day.\n",
    "    clf.fit(X[i], Y[i])\n",
    "    \n",
    "    # i + 1 being the next day on which the model is being tested on. \n",
    "    Y_preds = clf.predict(X[i + 1])\n",
    "    rate = 1 - accuracy_score(Y[i + 1], Y_preds)\n",
    "    error_rates_svm_daily.append(rate)\n",
    "    print(\"Error-rate Day {}   : {}\".format(i + 1, rate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f0db3e",
   "metadata": {},
   "source": [
    "### SVM-multi-once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393457c",
   "metadata": {},
   "source": [
    "**Train once on data for days 0-16 (train_set_size) and (evaluate for those days)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed3c0efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error-rate Day 1   : 0.02705000000000002\n",
      "Error-rate Day 2   : 0.019000000000000017\n",
      "Error-rate Day 3   : 0.018000000000000016\n",
      "Error-rate Day 4   : 0.019649999999999945\n",
      "Error-rate Day 5   : 0.01990000000000003\n",
      "Error-rate Day 6   : 0.01824999999999999\n",
      "Error-rate Day 7   : 0.021499999999999964\n",
      "Error-rate Day 8   : 0.01795000000000002\n",
      "Error-rate Day 9   : 0.020950000000000024\n",
      "Error-rate Day 10   : 0.018900000000000028\n",
      "Error-rate Day 11   : 0.01739999999999997\n",
      "Error-rate Day 12   : 0.016750000000000043\n",
      "Error-rate Day 13   : 0.01319999999999999\n",
      "Error-rate Day 14   : 0.018850000000000033\n",
      "Error-rate Day 15   : 0.01419999999999999\n",
      "Error-rate Day 16   : 0.013800000000000034\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(C=0.01)\n",
    "\n",
    "error_rates_svm_multi_once =  []\n",
    "\n",
    "for i in range(1, train_set_size):\n",
    "    rate = train_and_evaluate_day(0, i, clf)\n",
    "    error_rates_svm_multi_once.append(rate)\n",
    "    print(\"Error-rate Day {}   : {}\".format(i, rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86ed412",
   "metadata": {},
   "source": [
    "**Evaluate for the remaining days**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2701199c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error-rate Day 17   : 0.014000000000000012\n",
      "Error-rate Day 18   : 0.014650000000000052\n",
      "Error-rate Day 19   : 0.013449999999999962\n",
      "Error-rate Day 20   : 0.01429999999999998\n",
      "Error-rate Day 21   : 0.018950000000000022\n",
      "Error-rate Day 22   : 0.014149999999999996\n",
      "Error-rate Day 23   : 0.018750000000000044\n",
      "Error-rate Day 24   : 0.021399999999999975\n",
      "Error-rate Day 25   : 0.02190000000000003\n",
      "Error-rate Day 26   : 0.01685000000000003\n",
      "Error-rate Day 27   : 0.01759999999999995\n",
      "Error-rate Day 28   : 0.017549999999999955\n",
      "Error-rate Day 29   : 0.020399999999999974\n",
      "Error-rate Day 30   : 0.028349999999999986\n",
      "Error-rate Day 31   : 0.027100000000000013\n",
      "Error-rate Day 32   : 0.027599999999999958\n",
      "Error-rate Day 33   : 0.024499999999999966\n",
      "Error-rate Day 34   : 0.015599999999999947\n",
      "Error-rate Day 35   : 0.02629999999999999\n",
      "Error-rate Day 36   : 0.01475000000000004\n",
      "Error-rate Day 37   : 0.014100000000000001\n",
      "Error-rate Day 38   : 0.03159999999999996\n",
      "Error-rate Day 39   : 0.03359999999999996\n",
      "Error-rate Day 40   : 0.024249999999999994\n",
      "Error-rate Day 41   : 0.018299999999999983\n",
      "Error-rate Day 42   : 0.02454999999999996\n",
      "Error-rate Day 43   : 0.021649999999999947\n",
      "Error-rate Day 44   : 0.015650000000000053\n",
      "Error-rate Day 45   : 0.01538461538461533\n",
      "Error-rate Day 46   : 0.016800000000000037\n",
      "Error-rate Day 47   : 0.01805000000000001\n",
      "Error-rate Day 48   : 0.024950000000000028\n",
      "Error-rate Day 49   : 0.028299999999999992\n",
      "Error-rate Day 50   : 0.02344999999999997\n",
      "Error-rate Day 51   : 0.020000000000000018\n",
      "Error-rate Day 52   : 0.019950000000000023\n",
      "Error-rate Day 53   : 0.024900000000000033\n",
      "Error-rate Day 54   : 0.015800000000000036\n",
      "Error-rate Day 55   : 0.016900000000000026\n",
      "Error-rate Day 56   : 0.018650000000000055\n",
      "Error-rate Day 57   : 0.015750000000000042\n",
      "Error-rate Day 58   : 0.018449999999999966\n",
      "Error-rate Day 59   : 0.01715\n",
      "Error-rate Day 60   : 0.019100000000000006\n",
      "Error-rate Day 61   : 0.019950000000000023\n",
      "Error-rate Day 62   : 0.01959999999999995\n",
      "Error-rate Day 63   : 0.0242\n",
      "Error-rate Day 64   : 0.019199999999999995\n",
      "Error-rate Day 65   : 0.021850000000000036\n",
      "Error-rate Day 66   : 0.01759999999999995\n",
      "Error-rate Day 67   : 0.019199999999999995\n",
      "Error-rate Day 68   : 0.016750000000000043\n",
      "Error-rate Day 69   : 0.014449999999999963\n",
      "Error-rate Day 70   : 0.017850000000000033\n",
      "Error-rate Day 71   : 0.016800000000000037\n",
      "Error-rate Day 72   : 0.017000000000000015\n",
      "Error-rate Day 73   : 0.017299999999999982\n",
      "Error-rate Day 74   : 0.015000000000000013\n",
      "Error-rate Day 75   : 0.019649999999999945\n",
      "Error-rate Day 76   : 0.02739999999999998\n",
      "Error-rate Day 77   : 0.01805000000000001\n",
      "Error-rate Day 78   : 0.028750000000000053\n",
      "Error-rate Day 79   : 0.03134999999999999\n",
      "Error-rate Day 80   : 0.02795000000000003\n",
      "Error-rate Day 81   : 0.020449999999999968\n",
      "Error-rate Day 82   : 0.022299999999999986\n",
      "Error-rate Day 83   : 0.021050000000000013\n",
      "Error-rate Day 84   : 0.02210000000000001\n",
      "Error-rate Day 85   : 0.028750000000000053\n",
      "Error-rate Day 86   : 0.02090000000000003\n",
      "Error-rate Day 87   : 0.02100000000000002\n",
      "Error-rate Day 88   : 0.020549999999999957\n",
      "Error-rate Day 89   : 0.027900000000000036\n",
      "Error-rate Day 90   : 0.02464999999999995\n",
      "Error-rate Day 91   : 0.020000000000000018\n",
      "Error-rate Day 92   : 0.023499999999999965\n",
      "Error-rate Day 93   : 0.0232\n",
      "Error-rate Day 94   : 0.022299999999999986\n",
      "Error-rate Day 95   : 0.010050000000000003\n",
      "Error-rate Day 96   : 0.018100000000000005\n",
      "Error-rate Day 97   : 0.01759999999999995\n",
      "Error-rate Day 98   : 0.033499999999999974\n",
      "Error-rate Day 99   : 0.02585000000000004\n",
      "Error-rate Day 100   : 0.023399999999999976\n",
      "Error-rate Day 101   : 0.023050000000000015\n",
      "Error-rate Day 102   : 0.023150000000000004\n",
      "Error-rate Day 103   : 0.017800000000000038\n",
      "Error-rate Day 104   : 0.013449999999999962\n",
      "Error-rate Day 105   : 0.018449999999999966\n",
      "Error-rate Day 106   : 0.016700000000000048\n",
      "Error-rate Day 107   : 0.01485000000000003\n",
      "Error-rate Day 108   : 0.024950000000000028\n",
      "Error-rate Day 109   : 0.015549999999999953\n",
      "Error-rate Day 110   : 0.017349999999999977\n",
      "Error-rate Day 111   : 0.014950000000000019\n",
      "Error-rate Day 112   : 0.01539999999999997\n",
      "Error-rate Day 113   : 0.01739999999999997\n",
      "Error-rate Day 114   : 0.016249999999999987\n",
      "Error-rate Day 115   : 0.017249999999999988\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(train_set_size, num_of_days):\n\u001b[0;32m----> 2\u001b[0m     Y_preds \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m accuracy_score(Y[i], Y_preds)\n\u001b[1;32m      4\u001b[0m     error_rates_svm_multi_once\u001b[38;5;241m.\u001b[39mappend(rate)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_base.py:425\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    427\u001b[0m         indices \u001b[38;5;241m=\u001b[39m (scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_base.py:407\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03mPredict confidence scores for samples.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03m    this class would be predicted.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 407\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:720\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[1;32m    719\u001b[0m     _ensure_no_complex_data(array)\n\u001b[0;32m--> 720\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_sparse_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# of warnings context manager.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:455\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# ensure correct sparse format\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spmatrix\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m accept_sparse:\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;66;03m# create new with correct sparse\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m         spmatrix \u001b[38;5;241m=\u001b[39m \u001b[43mspmatrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m         changed_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m accept_sparse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# any other type\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/sparse/_base.py:376\u001b[0m, in \u001b[0;36mspmatrix.asformat\u001b[0;34m(self, format, copy)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# Forward the copy kwarg, if it's accepted.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_method()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/sparse/_csc.py:140\u001b[0m, in \u001b[0;36mcsc_matrix.tocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    137\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[1;32m    138\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz, dtype\u001b[38;5;241m=\u001b[39mupcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m--> 140\u001b[0m \u001b[43mcsc_tocsr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m          \u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m          \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_csr_container(\n\u001b[1;32m    149\u001b[0m     (data, indices, indptr),\n\u001b[1;32m    150\u001b[0m     shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    151\u001b[0m )\n\u001b[1;32m    152\u001b[0m A\u001b[38;5;241m.\u001b[39mhas_sorted_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(train_set_size, num_of_days):\n",
    "    Y_preds = clf.predict(X[i])\n",
    "    rate = 1 - accuracy_score(Y[i], Y_preds)\n",
    "    error_rates_svm_multi_once.append(rate)\n",
    "    print(\"Error-rate Day {}   : {}\".format(i,rate))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19a3e3f",
   "metadata": {},
   "source": [
    "### SVM-multi\n",
    "**Train on data of previous 0-16 days (train_set_size) and predict of successive day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c5432c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC(C=0.01)\n",
    "\n",
    "error_rates_svm_multi = []\n",
    "for curr_day in range(1, num_of_days):\n",
    "    \n",
    "    if (curr_day != 45): # skip faulty data of day 45\n",
    "        lower_bound = max(0, ((curr_day - 1) - train_set_size))\n",
    "        upper_bound = curr_day\n",
    "        rate = train_and_evaluate_day(lower_bound, curr_day, clf)\n",
    "        error_rates_svm_multi.append(rate)\n",
    "        print(\"Error-rate Day {}   : {}\".format(curr_day, rate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed9da3",
   "metadata": {},
   "source": [
    "### Passive Aggressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = PassiveAggressiveClassifier(C=0.001, random_state = 123)\n",
    "\n",
    "error_rates_pa = learn_incremental(clf, batch_size)\n",
    "\n",
    "cnt = 0\n",
    "for x in error_rates_pa:    \n",
    "    print(\"Error-rate Day {}   : {}\".format(cnt, x))\n",
    "    cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a782d60",
   "metadata": {},
   "source": [
    "**There are two cleanup functions provided which may be used to catch outliers in the results**\n",
    "\n",
    "*For further information on their use in this case, please refer to the accompanying paper*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db4489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(x, y):\n",
    "    \n",
    "    # Cleanup outliers in data\n",
    "    outliers = []\n",
    "    for i in range(len(y)):\n",
    "        if (y[i] > 4.5 or y[i] < 0):\n",
    "            outliers = np.append(outliers, i)\n",
    "    \n",
    "    offset = 0\n",
    "    for outl in outliers:\n",
    "        y = np.delete(y, int(outl) - offset)\n",
    "        x = x[:-1]\n",
    "        offset = offset + 1\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dbb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup2(x, y, top, bot):\n",
    "    \n",
    "    # Cleanup outliers in data\n",
    "    outliers = []\n",
    "    for i in range(len(y)):\n",
    "        if (y[i] > top or y[i] < bot):\n",
    "            outliers = np.append(outliers, i)\n",
    "    \n",
    "    offset = 0\n",
    "    for outl in outliers:\n",
    "        y = np.delete(y, int(outl) - offset)\n",
    "        x = x[:-1]\n",
    "        offset = offset + 1\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd33c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calc_line(x, y):\n",
    "    \n",
    "    # create polynomial equation and calculate line\n",
    "    theta = np.polyfit(x, y, 8)\n",
    "    return theta[8] + theta[7] * pow(x, 1) + theta[6] * pow(x, 2) + theta[5] * pow(x, 3) + theta[4] * pow(x, 4) + theta[3] * pow(x, 5) + theta[2] * pow(x, 6) + theta[1] * pow(x, 7) + theta[0] * pow(x, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca59e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot(y, color, marker, linestyle, scatter, label, cleanup):\n",
    "    \n",
    "    # Set up the day_indexes with the missing 45th day in mind\n",
    "    x = np.arange(1, 120) \n",
    "    \n",
    "    # attend to data size imbalances (day 45 outages)\n",
    "    if (y.shape[0] < x.shape[0]):\n",
    "        x = x[:-1]\n",
    "        \n",
    "    y = y * 100\n",
    "    \n",
    "    if (cleanup):\n",
    "        x, y = cleanup(x, y)\n",
    "    \n",
    "        if (color == 'r'):\n",
    "            x, y = cleanup2(x, y, 3, 1)\n",
    "    \n",
    "    if (scatter):\n",
    "        plt.scatter(x, y, c=color)\n",
    "    \n",
    "    y = _calc_line(x, y)\n",
    "    plt.plot(x, y, \"{}{}{}\".format(marker, color, linestyle), markevery=5, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4cce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot8degree(error_rates_pa, error_rates_svm_once, error_rates_svm_daily,\n",
    "                error_rates_svm_multi_once, error_rates_svm_multi, batch_size, scatter = False, cleanup = False):\n",
    "\n",
    "    if (error_rates_pa is not None):\n",
    "        _plot(np.array(error_rates_pa), 'r', 'v', '-', scatter, \"PA\", cleanup)\n",
    "        \n",
    "    if (error_rates_svm_once is not None):\n",
    "        _plot(np.array(error_rates_svm_once), 'k', 's', '-', scatter, \"SVM-once\", cleanup)\n",
    "        \n",
    "    if (error_rates_svm_daily is not None):\n",
    "        _plot(np.array(error_rates_svm_daily), 'm', '+', '--', scatter, \"SVM-daily\", cleanup)\n",
    "    \n",
    "    if (error_rates_svm_multi_once is not None):\n",
    "        _plot(np.array(error_rates_svm_multi_once), 'b', 'o', '--', scatter, \"SVM-multi-once\", cleanup)\n",
    "\n",
    "    if (error_rates_svm_multi is not None):\n",
    "        _plot(np.array(error_rates_svm_multi), 'g', 'x', '-', scatter, \"SVM-multi\")\n",
    "        \n",
    "    title = 'Experiment 1 with batch size {}'.format(batch_size)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Cumulative error rate (%)')\n",
    "    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#\n",
    "    if (not scatter):\n",
    "        plt.ylim([1,4])\n",
    "    plt.xlim([0,100])\n",
    "    plt.legend()\n",
    "    plt.savefig(\"{}-scatter_{}-cleanup_{}.svg\".format(title, scatter, cleanup), format='svg', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60920d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_errors(rates_string):\n",
    "    \n",
    "    arr = rates_string.split('\\n')\n",
    "    \n",
    "    for i in range(len(arr)):\n",
    "        arr[i] = arr[i].split(':')\n",
    "    \n",
    "    error_rates = []\n",
    "\n",
    "    for x in arr:\n",
    "        error_rates.append(float(x[1].strip()))\n",
    "        \n",
    "    return error_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca34dd2",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "svm_once = \"\"\"Error-rate Day 0   : 0.02625\n",
    "Error-rate Day 1   : 0.027000000000000024\n",
    "Error-rate Day 2   : 0.022050000000000014\n",
    "Error-rate Day 3   : 0.022199999999999998\n",
    "Error-rate Day 4   : 0.024700000000000055\n",
    "Error-rate Day 5   : 0.027100000000000013\n",
    "Error-rate Day 6   : 0.030200000000000005\n",
    "Error-rate Day 7   : 0.03444999999999998\n",
    "Error-rate Day 8   : 0.033499999999999974\n",
    "Error-rate Day 9   : 0.037250000000000005\n",
    "Error-rate Day 10   : 0.033950000000000036\n",
    "Error-rate Day 11   : 0.03259999999999996\n",
    "Error-rate Day 12   : 0.027750000000000052\n",
    "Error-rate Day 13   : 0.022399999999999975\n",
    "Error-rate Day 14   : 0.030299999999999994\n",
    "Error-rate Day 15   : 0.02664999999999995\n",
    "Error-rate Day 16   : 0.029349999999999987\n",
    "Error-rate Day 17   : 0.024950000000000028\n",
    "Error-rate Day 18   : 0.024950000000000028\n",
    "Error-rate Day 19   : 0.02510000000000001\n",
    "Error-rate Day 20   : 0.031850000000000045\n",
    "Error-rate Day 21   : 0.03939999999999999\n",
    "Error-rate Day 22   : 0.03854999999999997\n",
    "Error-rate Day 23   : 0.0363\n",
    "Error-rate Day 24   : 0.03774999999999995\n",
    "Error-rate Day 25   : 0.036599999999999966\n",
    "Error-rate Day 26   : 0.031749999999999945\n",
    "Error-rate Day 27   : 0.031000000000000028\n",
    "Error-rate Day 28   : 0.028800000000000048\n",
    "Error-rate Day 29   : 0.029200000000000004\n",
    "\n",
    "Error-rate Day 30   : 0.03759999999999997\n",
    "\n",
    "Error-rate Day 31   : 0.03885000000000005\n",
    "\n",
    "Error-rate Day 32   : 0.03664999999999996\n",
    "\n",
    "Error-rate Day 33   : 0.03705000000000003\n",
    "\n",
    "Error-rate Day 34   : 0.039000000000000035\n",
    "\n",
    "Error-rate Day 35   : 0.046599999999999975\n",
    "\n",
    "Error-rate Day 36   : 0.03859999999999997\n",
    "\n",
    "Error-rate Day 37   : 0.037150000000000016\n",
    "\n",
    "Error-rate Day 38   : 0.056499999999999995\n",
    "\n",
    "Error-rate Day 39   : 0.05945\n",
    "\n",
    "Error-rate Day 40   : 0.04039999999999999\n",
    "\n",
    "Error-rate Day 41   : 0.03134999999999999\n",
    "\n",
    "Error-rate Day 42   : 0.039000000000000035\n",
    "\n",
    "Error-rate Day 43   : 0.037900000000000045\n",
    "\n",
    "Error-rate Day 44   : 0.028100000000000014\n",
    "\n",
    "Error-rate Day 45   : 0.023076923076923106\n",
    "\n",
    "Error-rate Day 46   : 0.033050000000000024\n",
    "\n",
    "Error-rate Day 47   : 0.035699999999999954\n",
    "\n",
    "Error-rate Day 48   : 0.05900000000000005\n",
    "\n",
    "Error-rate Day 49   : 0.051899999999999946\n",
    "\n",
    "Error-rate Day 50   : 0.045499999999999985\n",
    "\n",
    "Error-rate Day 51   : 0.03874999999999995\n",
    "\n",
    "Error-rate Day 52   : 0.035499999999999976\n",
    "\n",
    "Error-rate Day 53   : 0.041749999999999954\n",
    "\n",
    "Error-rate Day 54   : 0.03639999999999999\n",
    "\n",
    "Error-rate Day 55   : 0.028449999999999975\n",
    "\n",
    "Error-rate Day 56   : 0.030299999999999994\n",
    "\n",
    "Error-rate Day 57   : 0.028900000000000037\n",
    "\n",
    "Error-rate Day 58   : 0.03069999999999995\n",
    "\n",
    "Error-rate Day 59   : 0.03115000000000001\n",
    "\n",
    "Error-rate Day 60   : 0.035150000000000015\n",
    "\n",
    "Error-rate Day 61   : 0.03885000000000005\n",
    "\n",
    "Error-rate Day 62   : 0.047699999999999965\n",
    "\n",
    "Error-rate Day 63   : 0.04530000000000001\n",
    "\n",
    "Error-rate Day 64   : 0.036699999999999955\n",
    "\n",
    "Error-rate Day 65   : 0.04085000000000005\n",
    "\n",
    "Error-rate Day 66   : 0.03654999999999997\n",
    "\n",
    "Error-rate Day 67   : 0.040449999999999986\n",
    "\n",
    "Error-rate Day 68   : 0.040649999999999964\n",
    "\n",
    "Error-rate Day 69   : 0.030100000000000016\n",
    "\n",
    "Error-rate Day 70   : 0.036050000000000026\n",
    "\n",
    "Error-rate Day 71   : 0.03385000000000005\n",
    "\n",
    "Error-rate Day 72   : 0.03225\n",
    "\n",
    "Error-rate Day 73   : 0.03369999999999995\n",
    "\n",
    "Error-rate Day 74   : 0.032399999999999984\n",
    "\n",
    "Error-rate Day 75   : 0.037900000000000045\n",
    "\n",
    "Error-rate Day 76   : 0.04200000000000004\n",
    "\n",
    "Error-rate Day 77   : 0.03115000000000001\n",
    "\n",
    "Error-rate Day 78   : 0.04025000000000001\n",
    "\n",
    "Error-rate Day 79   : 0.03785000000000005\n",
    "\n",
    "Error-rate Day 80   : 0.03849999999999998\n",
    "\n",
    "Error-rate Day 81   : 0.03359999999999996\n",
    "\n",
    "Error-rate Day 82   : 0.02905000000000002\n",
    "\n",
    "Error-rate Day 83   : 0.029349999999999987\n",
    "\n",
    "Error-rate Day 84   : 0.027449999999999974\n",
    "\n",
    "Error-rate Day 85   : 0.031850000000000045\n",
    "\n",
    "Error-rate Day 86   : 0.02959999999999996\n",
    "\n",
    "Error-rate Day 87   : 0.03134999999999999\n",
    "\n",
    "Error-rate Day 88   : 0.030950000000000033\n",
    "\n",
    "Error-rate Day 89   : 0.030950000000000033\n",
    "\n",
    "Error-rate Day 90   : 0.029900000000000038\n",
    "\n",
    "Error-rate Day 91   : 0.028249999999999997\n",
    "\n",
    "Error-rate Day 92   : 0.032850000000000046\n",
    "\n",
    "Error-rate Day 93   : 0.03259999999999996\n",
    "\n",
    "Error-rate Day 94   : 0.03115000000000001\n",
    "\n",
    "Error-rate Day 95   : 0.01805000000000001\n",
    "\n",
    "Error-rate Day 96   : 0.029100000000000015\n",
    "\n",
    "Error-rate Day 97   : 0.03639999999999999\n",
    "\n",
    "Error-rate Day 98   : 0.03869999999999996\n",
    "\n",
    "Error-rate Day 99   : 0.03915000000000002\n",
    "\n",
    "Error-rate Day 100   : 0.04359999999999997\n",
    "\n",
    "Error-rate Day 101   : 0.04015000000000002\n",
    "\n",
    "Error-rate Day 102   : 0.041200000000000014\n",
    "\n",
    "Error-rate Day 103   : 0.03534999999999999\n",
    "\n",
    "Error-rate Day 104   : 0.023299999999999987\n",
    "\n",
    "Error-rate Day 105   : 0.026900000000000035\n",
    "\n",
    "Error-rate Day 106   : 0.025800000000000045\n",
    "\n",
    "Error-rate Day 107   : 0.024599999999999955\n",
    "\n",
    "Error-rate Day 108   : 0.04190000000000005\n",
    "\n",
    "Error-rate Day 109   : 0.023900000000000032\n",
    "\n",
    "Error-rate Day 110   : 0.03259999999999996\n",
    "\n",
    "Error-rate Day 111   : 0.03749999999999998\n",
    "\n",
    "Error-rate Day 112   : 0.03590000000000004\n",
    "\n",
    "Error-rate Day 113   : 0.037150000000000016\n",
    "\n",
    "Error-rate Day 114   : 0.03810000000000002\n",
    "\n",
    "Error-rate Day 115   : 0.035050000000000026\n",
    "\n",
    "Error-rate Day 116   : 0.045950000000000046\n",
    "\n",
    "Error-rate Day 117   : 0.0383\n",
    "\n",
    "Error-rate Day 118   : 0.028800000000000048\n",
    "\n",
    "Error-rate Day 119   : 0.029349999999999987\"\"\"\n",
    "\n",
    "svm_once = os.linesep.join([s for s in svm_once.splitlines() if s])\n",
    "error_rates_svm_once = parse_errors(svm_once)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a96bc33",
   "metadata": {},
   "source": [
    "svm_daily = \"\"\"Error-rate Day 0   : 0.02625\n",
    "Error-rate Day 2   : 0.021299999999999986\n",
    "Error-rate Day 3   : 0.02124999999999999\n",
    "Error-rate Day 4   : 0.023950000000000027\n",
    "Error-rate Day 5   : 0.023150000000000004\n",
    "Error-rate Day 6   : 0.018299999999999983\n",
    "Error-rate Day 7   : 0.02300000000000002\n",
    "Error-rate Day 8   : 0.022150000000000003\n",
    "Error-rate Day 9   : 0.027000000000000024\n",
    "Error-rate Day 10   : 0.02429999999999999\n",
    "Error-rate Day 11   : 0.023050000000000015\n",
    "Error-rate Day 12   : 0.023399999999999976\n",
    "Error-rate Day 13   : 0.01849999999999996\n",
    "Error-rate Day 14   : 0.026100000000000012\n",
    "Error-rate Day 15   : 0.020449999999999968\n",
    "Error-rate Day 16   : 0.02100000000000002\n",
    "Error-rate Day 17   : 0.020299999999999985\n",
    "Error-rate Day 18   : 0.021399999999999975\n",
    "Error-rate Day 19   : 0.020299999999999985\n",
    "Error-rate Day 20   : 0.02300000000000002\n",
    "Error-rate Day 21   : 0.029900000000000038\n",
    "Error-rate Day 22   : 0.02100000000000002\n",
    "Error-rate Day 23   : 0.02675000000000005\n",
    "Error-rate Day 24   : 0.03154999999999997\n",
    "Error-rate Day 25   : 0.028900000000000037\n",
    "Error-rate Day 26   : 0.030000000000000027\n",
    "Error-rate Day 27   : 0.03244999999999998\n",
    "Error-rate Day 28   : 0.02464999999999995\n",
    "Error-rate Day 29   : 0.027900000000000036\n",
    "Error-rate Day 30   : 0.03485000000000005\n",
    "Error-rate Day 31   : 0.03359999999999996\n",
    "Error-rate Day 32   : 0.028900000000000037\n",
    "Error-rate Day 33   : 0.028100000000000014\n",
    "Error-rate Day 34   : 0.030850000000000044\n",
    "Error-rate Day 35   : 0.25144999999999995\n",
    "Error-rate Day 36   : 0.03115000000000001\n",
    "Error-rate Day 37   : 0.0\n",
    "Error-rate Day 38   : 0.3558\n",
    "Error-rate Day 39   : 0.04149999999999998\n",
    "Error-rate Day 40   : 0.030950000000000033\n",
    "Error-rate Day 41   : 0.02410000000000001\n",
    "Error-rate Day 42   : 0.032749999999999946\n",
    "Error-rate Day 43   : 0.030750000000000055\n",
    "Error-rate Day 44   : 0.021599999999999953\n",
    "Error-rate Day 45   : 0.023076923076923106\n",
    "Error-rate Day 46   : 0.12104999999999999\n",
    "Error-rate Day 47   : 0.024449999999999972\n",
    "Error-rate Day 48   : 0.035050000000000026\n",
    "Error-rate Day 49   : 0.030399999999999983\n",
    "Error-rate Day 50   : 0.030200000000000005\n",
    "Error-rate Day 51   : 0.025499999999999967\n",
    "Error-rate Day 52   : 0.028100000000000014\n",
    "Error-rate Day 53   : 0.034050000000000025\n",
    "Error-rate Day 54   : 0.02564999999999995\n",
    "Error-rate Day 55   : 0.023249999999999993\n",
    "Error-rate Day 56   : 0.02475000000000005\n",
    "Error-rate Day 57   : 0.03125\n",
    "Error-rate Day 58   : 0.023950000000000027\n",
    "Error-rate Day 59   : 0.023900000000000032\n",
    "Error-rate Day 60   : 0.02529999999999999\n",
    "Error-rate Day 61   : 0.023150000000000004\n",
    "Error-rate Day 62   : 0.027249999999999996\n",
    "Error-rate Day 63   : 0.030299999999999994\n",
    "Error-rate Day 64   : 0.021599999999999953\n",
    "Error-rate Day 65   : 0.02795000000000003\n",
    "Error-rate Day 66   : 0.028649999999999953\n",
    "Error-rate Day 67   : 0.024449999999999972\n",
    "Error-rate Day 68   : 0.023150000000000004\n",
    "Error-rate Day 69   : 0.018399999999999972\n",
    "Error-rate Day 70   : 0.023850000000000038\n",
    "Error-rate Day 71   : 0.023700000000000054\n",
    "Error-rate Day 72   : 0.020050000000000012\n",
    "Error-rate Day 73   : 0.020100000000000007\n",
    "Error-rate Day 74   : 0.017349999999999977\n",
    "Error-rate Day 75   : 0.030549999999999966\n",
    "Error-rate Day 76   : 0.03249999999999997\n",
    "Error-rate Day 77   : 0.027150000000000007\n",
    "Error-rate Day 78   : 0.031299999999999994\n",
    "Error-rate Day 79   : 0.031749999999999945\n",
    "Error-rate Day 80   : 0.030000000000000027\n",
    "Error-rate Day 81   : 0.026549999999999963\n",
    "Error-rate Day 82   : 0.021199999999999997\n",
    "Error-rate Day 83   : 0.01805000000000001\n",
    "Error-rate Day 84   : 0.022399999999999975\n",
    "Error-rate Day 85   : 0.02575000000000005\n",
    "Error-rate Day 86   : 0.022649999999999948\n",
    "Error-rate Day 87   : 0.019000000000000017\n",
    "Error-rate Day 88   : 0.021549999999999958\n",
    "Error-rate Day 89   : 0.01770000000000005\n",
    "Error-rate Day 90   : 0.012750000000000039\n",
    "Error-rate Day 91   : 0.02200000000000002\n",
    "Error-rate Day 92   : 0.02190000000000003\n",
    "Error-rate Day 93   : 0.023249999999999993\n",
    "Error-rate Day 94   : 0.023900000000000032\n",
    "Error-rate Day 95   : 0.01100000000000001\n",
    "Error-rate Day 96   : 0.019950000000000023\n",
    "Error-rate Day 97   : 0.020950000000000024\n",
    "Error-rate Day 98   : 0.020850000000000035\n",
    "Error-rate Day 99   : 0.022599999999999953\n",
    "Error-rate Day 100   : 0.024449999999999972\n",
    "Error-rate Day 101   : 0.02485000000000004\n",
    "Error-rate Day 102   : 0.025599999999999956\n",
    "Error-rate Day 103   : 0.020449999999999968\n",
    "Error-rate Day 104   : 0.02344999999999997\n",
    "Error-rate Day 105   : 0.02554999999999996\n",
    "Error-rate Day 106   : 0.02024999999999999\n",
    "Error-rate Day 107   : 0.020199999999999996\n",
    "Error-rate Day 108   : 0.03649999999999998\n",
    "Error-rate Day 109   : 0.02354999999999996\n",
    "Error-rate Day 110   : 0.022499999999999964\n",
    "Error-rate Day 111   : 0.02080000000000004\n",
    "Error-rate Day 112   : 0.020750000000000046\n",
    "Error-rate Day 113   : 0.021100000000000008\n",
    "Error-rate Day 114   : 0.020299999999999985\n",
    "Error-rate Day 115   : 0.02375000000000005\n",
    "Error-rate Day 116   : 0.03585000000000005\n",
    "Error-rate Day 117   : 0.025900000000000034\n",
    "Error-rate Day 118   : 0.024800000000000044\n",
    "Error-rate Day 119   : 0.021599999999999953\"\"\"\n",
    "\n",
    "error_rates_svm_daily = parse_errors(svm_daily)\n",
    "len(error_rates_svm_daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e5a44",
   "metadata": {},
   "source": [
    "svm_multi_once = \"\"\"Error-rate Day 0   : 0.02625\n",
    "Error-rate Day 1   : 0.02335\n",
    "Error-rate Day 2   : 0.0169\n",
    "Error-rate Day 3   : 0.0166\n",
    "Error-rate Day 4   : 0.0187\n",
    "Error-rate Day 5   : 0.0189\n",
    "Error-rate Day 6   : 0.017\n",
    "Error-rate Day 7   : 0.0193\n",
    "Error-rate Day 8   : 0.0178\n",
    "Error-rate Day 9   : 0.01935\n",
    "Error-rate Day 10   : 0.01625\n",
    "Error-rate Day 11   : 0.016\n",
    "Error-rate Day 12   : 0.01615\n",
    "Error-rate Day 13   : 0.01245\n",
    "Error-rate Day 14   : 0.0162\n",
    "Error-rate Day 15   : 0.01355\n",
    "Error-rate Day 16   : 0.0131\n",
    "Error-rate Day 17   : 0.013850000000000029\n",
    "Error-rate Day 18   : 0.014399999999999968\n",
    "Error-rate Day 19   : 0.012599999999999945\n",
    "Error-rate Day 20   : 0.01429999999999998\n",
    "Error-rate Day 21   : 0.019100000000000006\n",
    "Error-rate Day 22   : 0.01429999999999998\n",
    "Error-rate Day 23   : 0.018449999999999966\n",
    "Error-rate Day 24   : 0.02144999999999997\n",
    "Error-rate Day 25   : 0.02124999999999999\n",
    "Error-rate Day 26   : 0.016599999999999948\n",
    "Error-rate Day 27   : 0.017750000000000044\n",
    "Error-rate Day 28   : 0.017299999999999982\n",
    "Error-rate Day 29   : 0.019950000000000023\n",
    "Error-rate Day 30   : 0.027000000000000024\n",
    "Error-rate Day 31   : 0.026100000000000012\n",
    "Error-rate Day 32   : 0.026150000000000007\n",
    "Error-rate Day 33   : 0.023349999999999982\n",
    "Error-rate Day 34   : 0.015650000000000053\n",
    "Error-rate Day 35   : 0.024950000000000028\n",
    "Error-rate Day 36   : 0.015050000000000008\n",
    "Error-rate Day 37   : 0.014399999999999968\n",
    "Error-rate Day 38   : 0.03080000000000005\n",
    "Error-rate Day 39   : 0.03234999999999999\n",
    "Error-rate Day 40   : 0.02300000000000002\n",
    "Error-rate Day 41   : 0.016750000000000043\n",
    "Error-rate Day 42   : 0.024150000000000005\n",
    "Error-rate Day 43   : 0.02034999999999998\n",
    "Error-rate Day 44   : 0.015499999999999958\n",
    "Error-rate Day 45   : 0.01538461538461533\n",
    "Error-rate Day 46   : 0.016700000000000048\n",
    "Error-rate Day 47   : 0.017850000000000033\n",
    "Error-rate Day 48   : 0.02344999999999997\n",
    "Error-rate Day 49   : 0.026050000000000018\n",
    "Error-rate Day 50   : 0.02290000000000003\n",
    "Error-rate Day 51   : 0.01959999999999995\n",
    "Error-rate Day 52   : 0.019100000000000006\n",
    "Error-rate Day 53   : 0.024950000000000028\n",
    "Error-rate Day 54   : 0.015750000000000042\n",
    "Error-rate Day 55   : 0.01649999999999996\n",
    "Error-rate Day 56   : 0.018100000000000005\n",
    "Error-rate Day 57   : 0.014800000000000035\n",
    "Error-rate Day 58   : 0.01695000000000002\n",
    "Error-rate Day 59   : 0.01705000000000001\n",
    "Error-rate Day 60   : 0.01824999999999999\n",
    "Error-rate Day 61   : 0.018100000000000005\n",
    "Error-rate Day 62   : 0.01815\n",
    "Error-rate Day 63   : 0.023499999999999965\n",
    "Error-rate Day 64   : 0.019199999999999995\n",
    "Error-rate Day 65   : 0.021700000000000053\n",
    "Error-rate Day 66   : 0.016449999999999965\n",
    "Error-rate Day 67   : 0.01815\n",
    "Error-rate Day 68   : 0.01605000000000001\n",
    "Error-rate Day 69   : 0.01419999999999999\n",
    "Error-rate Day 70   : 0.017199999999999993\n",
    "Error-rate Day 71   : 0.016349999999999976\n",
    "Error-rate Day 72   : 0.016249999999999987\n",
    "Error-rate Day 73   : 0.017199999999999993\n",
    "Error-rate Day 74   : 0.014050000000000007\n",
    "Error-rate Day 75   : 0.018900000000000028\n",
    "Error-rate Day 76   : 0.02664999999999995\n",
    "Error-rate Day 77   : 0.016700000000000048\n",
    "Error-rate Day 78   : 0.026549999999999963\n",
    "Error-rate Day 79   : 0.03125\n",
    "Error-rate Day 80   : 0.025800000000000045\n",
    "Error-rate Day 81   : 0.020549999999999957\n",
    "Error-rate Day 82   : 0.02364999999999995\n",
    "Error-rate Day 83   : 0.022599999999999953\n",
    "Error-rate Day 84   : 0.022050000000000014\n",
    "Error-rate Day 85   : 0.030449999999999977\n",
    "Error-rate Day 86   : 0.02070000000000005\n",
    "Error-rate Day 87   : 0.02124999999999999\n",
    "Error-rate Day 88   : 0.020499999999999963\n",
    "Error-rate Day 89   : 0.02939999999999998\n",
    "Error-rate Day 90   : 0.025150000000000006\n",
    "Error-rate Day 91   : 0.02070000000000005\n",
    "Error-rate Day 92   : 0.024050000000000016\n",
    "Error-rate Day 93   : 0.023399999999999976\n",
    "Error-rate Day 94   : 0.021850000000000036\n",
    "Error-rate Day 95   : 0.009700000000000042\n",
    "Error-rate Day 96   : 0.016249999999999987\n",
    "Error-rate Day 97   : 0.017299999999999982\n",
    "Error-rate Day 98   : 0.03485000000000005\n",
    "Error-rate Day 99   : 0.026499999999999968\n",
    "Error-rate Day 100   : 0.023150000000000004\n",
    "Error-rate Day 101   : 0.022499999999999964\n",
    "Error-rate Day 102   : 0.02310000000000001\n",
    "Error-rate Day 103   : 0.016349999999999976\n",
    "Error-rate Day 104   : 0.013050000000000006\n",
    "Error-rate Day 105   : 0.018000000000000016\n",
    "Error-rate Day 106   : 0.01605000000000001\n",
    "Error-rate Day 107   : 0.014549999999999952\n",
    "Error-rate Day 108   : 0.022399999999999975\n",
    "Error-rate Day 109   : 0.01529999999999998\n",
    "Error-rate Day 110   : 0.013700000000000045\n",
    "Error-rate Day 111   : 0.014499999999999957\n",
    "Error-rate Day 112   : 0.015599999999999947\n",
    "Error-rate Day 113   : 0.01695000000000002\n",
    "Error-rate Day 114   : 0.015700000000000047\n",
    "Error-rate Day 115   : 0.017349999999999977\n",
    "Error-rate Day 116   : 0.027200000000000002\n",
    "Error-rate Day 117   : 0.020850000000000035\n",
    "Error-rate Day 118   : 0.019199999999999995\n",
    "Error-rate Day 119   : 0.017000000000000015\"\"\"\n",
    "\n",
    "error_rates_svm_multi_once = parse_errors(svm_multi_once)\n",
    "len(error_rates_svm_multi_once)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a08264",
   "metadata": {},
   "source": [
    "svm_multi = \"\"\"Error-rate Day 0   : 0.02625\n",
    "Error-rate Day 1   : 0.02335\n",
    "Error-rate Day 2   : 0.0169\n",
    "Error-rate Day 3   : 0.0166\n",
    "Error-rate Day 4   : 0.0187\n",
    "Error-rate Day 5   : 0.0189\n",
    "Error-rate Day 6   : 0.017\n",
    "Error-rate Day 7   : 0.0193\n",
    "Error-rate Day 8   : 0.0178\n",
    "Error-rate Day 9   : 0.01935\n",
    "Error-rate Day 10   : 0.01625\n",
    "Error-rate Day 11   : 0.016\n",
    "Error-rate Day 12   : 0.01615\n",
    "Error-rate Day 13   : 0.01245\n",
    "Error-rate Day 14   : 0.0162\n",
    "Error-rate Day 15   : 0.01355\n",
    "Error-rate Day 16   : 0.0131\n",
    "Error-rate Day 17   : 0.01325\n",
    "Error-rate Day 18   : 0.01365\n",
    "Error-rate Day 19   : 0.0114\n",
    "Error-rate Day 20   : 0.01335\n",
    "Error-rate Day 21   : 0.01575\n",
    "Error-rate Day 22   : 0.0126\n",
    "Error-rate Day 23   : 0.01655\n",
    "Error-rate Day 24   : 0.0173\n",
    "Error-rate Day 25   : 0.01805\n",
    "Error-rate Day 26   : 0.0129\n",
    "Error-rate Day 27   : 0.01345\n",
    "Error-rate Day 28   : 0.01485\n",
    "Error-rate Day 29   : 0.01655\n",
    "Error-rate Day 30   : 0.0232\n",
    "Error-rate Day 31   : 0.0215\n",
    "Error-rate Day 32   : 0.01725\n",
    "Error-rate Day 33   : 0.0167\n",
    "Error-rate Day 34   : 0.01655\n",
    "Error-rate Day 35   : 0.02245\n",
    "Error-rate Day 36   : 0.01405\n",
    "Error-rate Day 37   : 0.0112\n",
    "Error-rate Day 38   : 0.02665\n",
    "Error-rate Day 39   : 0.0319\n",
    "Error-rate Day 40   : 0.02075\n",
    "Error-rate Day 41   : 0.0138\n",
    "Error-rate Day 42   : 0.021\n",
    "Error-rate Day 43   : 0.01715\n",
    "Error-rate Day 44   : 0.01185\n",
    "Error-rate Day 46   : 0.0136\n",
    "Error-rate Day 47   : 0.01465\n",
    "Error-rate Day 48   : 0.0166\n",
    "Error-rate Day 49   : 0.01885\n",
    "Error-rate Day 50   : 0.0193\n",
    "Error-rate Day 51   : 0.01515\n",
    "Error-rate Day 52   : 0.0164\n",
    "Error-rate Day 53   : 0.02\n",
    "Error-rate Day 54   : 0.01315\n",
    "Error-rate Day 55   : 0.01465\n",
    "Error-rate Day 56   : 0.0154\n",
    "Error-rate Day 57   : 0.0119\n",
    "Error-rate Day 58   : 0.01245\n",
    "Error-rate Day 59   : 0.0127\n",
    "Error-rate Day 60   : 0.0128\n",
    "Error-rate Day 61   : 0.01235\n",
    "Error-rate Day 62   : 0.0145\n",
    "Error-rate Day 63   : 0.0168\n",
    "Error-rate Day 64   : 0.01335\n",
    "Error-rate Day 65   : 0.01715\n",
    "Error-rate Day 66   : 0.01275\n",
    "Error-rate Day 67   : 0.01375\n",
    "Error-rate Day 68   : 0.01295\n",
    "Error-rate Day 69   : 0.0109\n",
    "Error-rate Day 70   : 0.01495\n",
    "Error-rate Day 71   : 0.01635\n",
    "Error-rate Day 72   : 0.0144\n",
    "Error-rate Day 73   : 0.01425\n",
    "Error-rate Day 74   : 0.01265\n",
    "Error-rate Day 75   : 0.01635\n",
    "Error-rate Day 76   : 0.0243\n",
    "Error-rate Day 77   : 0.01295\n",
    "Error-rate Day 78   : 0.0199\n",
    "Error-rate Day 79   : 0.0287\n",
    "Error-rate Day 80   : 0.01995\n",
    "Error-rate Day 81   : 0.0181\n",
    "Error-rate Day 82   : 0.01065\n",
    "Error-rate Day 83   : 0.01215\n",
    "Error-rate Day 84   : 0.01215\n",
    "Error-rate Day 85   : 0.01495\n",
    "Error-rate Day 86   : 0.0122\n",
    "Error-rate Day 87   : 0.00975\n",
    "Error-rate Day 88   : 0.01235\n",
    "Error-rate Day 89   : 0.0104\n",
    "Error-rate Day 90   : 0.00885\n",
    "Error-rate Day 91   : 0.0102\n",
    "Error-rate Day 92   : 0.01235\n",
    "Error-rate Day 93   : 0.0132\n",
    "Error-rate Day 94   : 0.01\n",
    "Error-rate Day 95   : 0.006\n",
    "Error-rate Day 96   : 0.01005\n",
    "Error-rate Day 97   : 0.01525\n",
    "Error-rate Day 98   : 0.0153\n",
    "Error-rate Day 99   : 0.0149\n",
    "Error-rate Day 100   : 0.0173\n",
    "Error-rate Day 101   : 0.01695\n",
    "Error-rate Day 102   : 0.0188\n",
    "Error-rate Day 103   : 0.0136\n",
    "Error-rate Day 104   : 0.00895\n",
    "Error-rate Day 105   : 0.0143\n",
    "Error-rate Day 106   : 0.0105\n",
    "Error-rate Day 107   : 0.01\n",
    "Error-rate Day 108   : 0.0135\n",
    "Error-rate Day 109   : 0.0106\n",
    "Error-rate Day 110   : 0.01\n",
    "Error-rate Day 111   : 0.0115\n",
    "Error-rate Day 112   : 0.01335\n",
    "Error-rate Day 113   : 0.01335\n",
    "Error-rate Day 114   : 0.0121\n",
    "Error-rate Day 115   : 0.01365\n",
    "Error-rate Day 116   : 0.019\n",
    "Error-rate Day 117   : 0.0101\n",
    "Error-rate Day 118   : 0.01175\n",
    "Error-rate Day 119   : 0.0118\"\"\"\n",
    "\n",
    "error_rates_svm_multi = parse_errors(svm_multi)\n",
    "len(error_rates_svm_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3bb99",
   "metadata": {},
   "source": [
    "pa = \"\"\"Error-rate Day 0   : 0.0515625\n",
    "Error-rate Day 1   : 0.0319\n",
    "Error-rate Day 2   : 0.0248\n",
    "Error-rate Day 3   : 0.0234\n",
    "Error-rate Day 4   : 0.0265\n",
    "Error-rate Day 5   : 0.02545\n",
    "Error-rate Day 6   : 0.02245\n",
    "Error-rate Day 7   : 0.02585\n",
    "Error-rate Day 8   : 0.02355\n",
    "Error-rate Day 9   : 0.02865\n",
    "Error-rate Day 10   : 0.02505\n",
    "Error-rate Day 11   : 0.0227\n",
    "Error-rate Day 12   : 0.02365\n",
    "Error-rate Day 13   : 0.0193\n",
    "Error-rate Day 14   : 0.02435\n",
    "Error-rate Day 15   : 0.01945\n",
    "Error-rate Day 16   : 0.02055\n",
    "Error-rate Day 17   : 0.0196\n",
    "Error-rate Day 18   : 0.02\n",
    "Error-rate Day 19   : 0.0184\n",
    "Error-rate Day 20   : 0.02065\n",
    "Error-rate Day 21   : 0.0265\n",
    "Error-rate Day 22   : 0.0227\n",
    "Error-rate Day 23   : 0.0244\n",
    "Error-rate Day 24   : 0.0276\n",
    "Error-rate Day 25   : 0.02715\n",
    "Error-rate Day 26   : 0.018\n",
    "Error-rate Day 27   : 0.0236\n",
    "Error-rate Day 28   : 0.02165\n",
    "Error-rate Day 29   : 0.024\n",
    "Error-rate Day 30   : 0.0312\n",
    "Error-rate Day 31   : 0.02725\n",
    "Error-rate Day 32   : 0.02655\n",
    "Error-rate Day 33   : 0.02575\n",
    "Error-rate Day 34   : 0.00055\n",
    "Error-rate Day 35   : 0.03055\n",
    "Error-rate Day 36   : 0.00455\n",
    "Error-rate Day 37   : 0.001\n",
    "Error-rate Day 38   : 0.0368\n",
    "Error-rate Day 39   : 0.03635\n",
    "Error-rate Day 40   : 0.02495\n",
    "Error-rate Day 41   : 0.0202\n",
    "Error-rate Day 42   : 0.02645\n",
    "Error-rate Day 43   : 0.0233\n",
    "Error-rate Day 44   : 0.01545\n",
    "Error-rate Day 45   : 0.0213\n",
    "Error-rate Day 46   : 0.0198\n",
    "Error-rate Day 47   : 0.02435\n",
    "Error-rate Day 48   : 0.0271\n",
    "Error-rate Day 49   : 0.0262\n",
    "Error-rate Day 50   : 0.02145\n",
    "Error-rate Day 51   : 0.0215\n",
    "Error-rate Day 52   : 0.025\n",
    "Error-rate Day 53   : 0.0184\n",
    "Error-rate Day 54   : 0.01765\n",
    "Error-rate Day 55   : 0.01875\n",
    "Error-rate Day 56   : 0.01845\n",
    "Error-rate Day 57   : 0.01795\n",
    "Error-rate Day 58   : 0.01845\n",
    "Error-rate Day 59   : 0.0187\n",
    "Error-rate Day 60   : 0.0171\n",
    "Error-rate Day 61   : 0.0184\n",
    "Error-rate Day 62   : 0.02235\n",
    "Error-rate Day 63   : 0.01795\n",
    "Error-rate Day 64   : 0.0218\n",
    "Error-rate Day 65   : 0.0176\n",
    "Error-rate Day 66   : 0.01795\n",
    "Error-rate Day 67   : 0.0176\n",
    "Error-rate Day 68   : 0.015\n",
    "Error-rate Day 69   : 0.01715\n",
    "Error-rate Day 70   : 0.01915\n",
    "Error-rate Day 71   : 0.018\n",
    "Error-rate Day 72   : 0.0175\n",
    "Error-rate Day 73   : 0.01565\n",
    "Error-rate Day 74   : 0.0198\n",
    "Error-rate Day 75   : 0.0242\n",
    "Error-rate Day 76   : 0.0161\n",
    "Error-rate Day 77   : 0.0197\n",
    "Error-rate Day 78   : 0.02385\n",
    "Error-rate Day 79   : 0.02215\n",
    "Error-rate Day 80   : 0.02125\n",
    "Error-rate Day 81   : 0.01245\n",
    "Error-rate Day 82   : 0.0138\n",
    "Error-rate Day 83   : 0.0161\n",
    "Error-rate Day 84   : 0.0184\n",
    "Error-rate Day 85   : 0.0151\n",
    "Error-rate Day 86   : 0.0125\n",
    "Error-rate Day 87   : 0.01405\n",
    "Error-rate Day 88   : 0.0115\n",
    "Error-rate Day 89   : 0.00825\n",
    "Error-rate Day 90   : 0.01265\n",
    "Error-rate Day 91   : 0.01625\n",
    "Error-rate Day 92   : 0.0169\n",
    "Error-rate Day 93   : 0.0131\n",
    "Error-rate Day 94   : 0.0072\n",
    "Error-rate Day 95   : 0.01355\n",
    "Error-rate Day 96   : 0.01475\n",
    "Error-rate Day 97   : 0.01425\n",
    "Error-rate Day 98   : 0.01635\n",
    "Error-rate Day 99   : 0.01925\n",
    "Error-rate Day 100   : 0.01845\n",
    "Error-rate Day 101   : 0.01995\n",
    "Error-rate Day 102   : 0.0145\n",
    "Error-rate Day 103   : 0.0122\n",
    "Error-rate Day 104   : 0.0161\n",
    "Error-rate Day 105   : 0.01275\n",
    "Error-rate Day 106   : 0.01255\n",
    "Error-rate Day 107   : 0.01735\n",
    "Error-rate Day 108   : 0.01315\n",
    "Error-rate Day 109   : 0.01395\n",
    "Error-rate Day 110   : 0.01335\n",
    "Error-rate Day 111   : 0.015\n",
    "Error-rate Day 112   : 0.01535\n",
    "Error-rate Day 113   : 0.01555\n",
    "Error-rate Day 114   : 0.01675\n",
    "Error-rate Day 115   : 0.02335\n",
    "Error-rate Day 116   : 0.01415\n",
    "Error-rate Day 117   : 0.01465\n",
    "Error-rate Day 118   : 0.01465\"\"\" \n",
    "\n",
    "error_rates_pa = parse_errors(pa)\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e56879",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot8degree(error_rates_pa, error_rates_svm_once, error_rates_svm_daily,\n",
    "                error_rates_svm_multi_once, error_rates_svm_multi, batch_size, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a87e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot8degree(error_rates_pa, error_rates_svm_once, error_rates_svm_daily,\n",
    "                error_rates_svm_multi_once, error_rates_svm_multi, batch_size, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0161e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot8degree(error_rates_pa, error_rates_svm_once, error_rates_svm_daily,\n",
    "                error_rates_svm_multi_once, error_rates_svm_multi, batch_size, True, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
