{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a6e22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "data = scipy.io.loadmat('../../data/url.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9fc2f1",
   "metadata": {},
   "source": [
    "**create list for labels and data, where one entry is the data for the day with this index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c361a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_of_days = 120\n",
    "X, Y = [], []\n",
    "\n",
    "for i in range(num_of_days):\n",
    "    day_data = data[\"Day\" + str(i)]\n",
    "    X.append(day_data[0][0][0])\n",
    "    Y.append(day_data[0][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482f91d",
   "metadata": {},
   "source": [
    "**continous learn classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503737e1",
   "metadata": {},
   "source": [
    "### single urls\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(random_state=123)\n",
    "\n",
    "err = 0\n",
    "for i in range(1): # looping through days\n",
    "    \n",
    "    # change X to row format for faster slicing row-wise.\n",
    "    X_curr_day, Y_curr_day = X[i].tocsr(), Y[i]\n",
    "    \n",
    "    for j in range(X_curr_day.shape[0]): # looping through individual urls\n",
    "        X_curr_url, Y_curr_url = X_curr_day[j,:], Y_curr_day[j] \n",
    "        \n",
    "        if (j > 0):\n",
    "            if (clf.predict(X_curr_url) != Y_curr_url):\n",
    "                err = err + 1\n",
    "        \n",
    "        clf.partial_fit(X_curr_url, Y_curr_url, classes=list(range(2))) # Continous fitting of urls and label\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e626e75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start = 17:03:51.841272\n",
      "0\n",
      "0.0486875\n",
      "1\n",
      "0.0353\n",
      "2\n",
      "0.0306\n",
      "3\n",
      "0.0289\n",
      "4\n",
      "0.0323\n",
      "5\n",
      "0.02635\n",
      "6\n",
      "0.02515\n",
      "7\n",
      "0.03175\n",
      "8\n",
      "0.02925\n",
      "9\n",
      "0.03725\n",
      "10\n",
      "0.03095\n",
      "11\n",
      "0.0251\n",
      "12\n",
      "0.0274\n",
      "13\n",
      "0.02105\n",
      "14\n",
      "0.0241\n",
      "15\n",
      "0.0207\n",
      "16\n",
      "0.02285\n",
      "17\n",
      "0.0202\n",
      "18\n",
      "0.0229\n",
      "19\n",
      "0.01685\n",
      "20\n",
      "0.02295\n",
      "21\n",
      "0.02875\n",
      "22\n",
      "0.02455\n",
      "23\n",
      "0.02655\n",
      "24\n",
      "0.03065\n",
      "25\n",
      "0.0352\n",
      "26\n",
      "0.02105\n",
      "27\n",
      "0.02385\n",
      "28\n",
      "0.02665\n",
      "29\n",
      "0.0245\n",
      "30\n",
      "0.0311\n",
      "31\n",
      "0.0289\n",
      "32\n",
      "0.0261\n",
      "33\n",
      "0.0274\n",
      "34\n",
      "0.0004\n",
      "35\n",
      "0.0327\n",
      "36\n",
      "0.00175\n",
      "37\n",
      "0.0009\n",
      "38\n",
      "0.0393\n",
      "39\n",
      "0.0376\n",
      "40\n",
      "0.02995\n",
      "41\n",
      "0.02395\n",
      "42\n",
      "0.0284\n",
      "43\n",
      "0.02635\n",
      "44\n",
      "0.0147\n",
      "46\n",
      "0.02495\n",
      "47\n",
      "0.022\n",
      "48\n",
      "0.02805\n",
      "49\n",
      "0.0317\n",
      "50\n",
      "0.03185\n",
      "51\n",
      "0.02325\n",
      "52\n",
      "0.02715\n",
      "53\n",
      "0.0301\n",
      "54\n",
      "0.02085\n",
      "55\n",
      "0.0227\n",
      "56\n",
      "0.02315\n",
      "57\n",
      "0.01995\n",
      "58\n",
      "0.02005\n",
      "59\n",
      "0.01775\n",
      "60\n",
      "0.0212\n",
      "61\n",
      "0.01825\n",
      "62\n",
      "0.0219\n",
      "63\n",
      "0.0246\n",
      "64\n",
      "0.01895\n",
      "65\n",
      "0.0258\n",
      "66\n",
      "0.0201\n",
      "67\n",
      "0.02045\n",
      "68\n",
      "0.0209\n",
      "69\n",
      "0.0165\n",
      "70\n",
      "0.02055\n",
      "71\n",
      "0.026\n",
      "72\n",
      "0.02075\n",
      "73\n",
      "0.0239\n",
      "74\n",
      "0.0197\n",
      "75\n",
      "0.02265\n",
      "76\n",
      "0.0225\n",
      "77\n",
      "0.0175\n",
      "78\n",
      "0.02075\n",
      "79\n",
      "0.0269\n",
      "80\n",
      "0.02595\n",
      "81\n",
      "0.02275\n",
      "82\n",
      "0.0129\n",
      "83\n",
      "0.0142\n",
      "84\n",
      "0.0179\n",
      "85\n",
      "0.0199\n",
      "86\n",
      "0.0148\n",
      "87\n",
      "0.0147\n",
      "88\n",
      "0.01525\n",
      "89\n",
      "0.0116\n",
      "90\n",
      "0.00955\n",
      "91\n",
      "0.014\n",
      "92\n",
      "0.01935\n",
      "93\n",
      "0.01765\n",
      "94\n",
      "0.01615\n",
      "95\n",
      "0.00845\n",
      "96\n",
      "0.0126\n",
      "97\n",
      "0.0175\n",
      "98\n",
      "0.0194\n",
      "99\n",
      "0.02095\n",
      "100\n",
      "0.0223\n",
      "101\n",
      "0.0214\n",
      "102\n",
      "0.02205\n",
      "103\n",
      "0.01785\n",
      "104\n",
      "0.0142\n",
      "105\n",
      "0.0197\n",
      "106\n",
      "0.0162\n",
      "107\n",
      "0.01625\n",
      "108\n",
      "0.0193\n",
      "109\n",
      "0.01685\n",
      "110\n",
      "0.012\n",
      "111\n",
      "0.01625\n",
      "112\n",
      "0.01685\n",
      "113\n",
      "0.01595\n",
      "114\n",
      "0.01585\n",
      "115\n",
      "0.0189\n",
      "116\n",
      "0.02225\n",
      "117\n",
      "0.014\n",
      "118\n",
      "0.01625\n",
      "119\n",
      "0.0154\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m fixed_features_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150000\u001b[39m \u001b[38;5;66;03m#150k features for training\u001b[39;00m\n\u001b[1;32m     18\u001b[0m select_ind \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, fixed_features_amount)\n\u001b[0;32m---> 19\u001b[0m X_curr_day \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[:,select_ind]\u001b[38;5;241m.\u001b[39mtocsr()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# split the data in slices of batch_size\u001b[39;00m\n\u001b[1;32m     22\u001b[0m batches_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(X_curr_day\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m batch_size)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "### url batches (n=100)\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from datetime import datetime\n",
    "\n",
    "clf = Perceptron(random_state=123)\n",
    "batch_size = 100\n",
    "err = 0\n",
    "\n",
    "start = datetime.now().time() # time object\n",
    "print(\"start =\", start)\n",
    "\n",
    "for i in range(num_of_days): # looping through days\n",
    "    \n",
    "    if (i != 45):\n",
    "        # change X to row format for faster slicing row-wise.\n",
    "        fixed_features_amount = 150000 #150k features for training\n",
    "        select_ind = np.arange(0, fixed_features_amount)\n",
    "        X_curr_day = X[i][:,select_ind].tocsr()\n",
    "    \n",
    "        # split the data in slices of batch_size\n",
    "        batches_amount = int(X_curr_day.shape[0] / batch_size)\n",
    "        Y_curr_day = np.array_split(Y[i], batches_amount)\n",
    "    \n",
    "        for j in range(batches_amount): # looping through individual urls\n",
    "            select_ind = np.arange(j * batch_size, (j+1) * batch_size)\n",
    "        \n",
    "            X_curr_url_batch, Y_curr_url_batch = X_curr_day[select_ind,:], Y_curr_day[j] \n",
    "        \n",
    "            # flatten y to 1d\n",
    "            Y_curr_url_batch = Y_curr_url_batch.ravel()\n",
    "        \n",
    "            if (j > 0):\n",
    "                Y_preds = clf.predict(X_curr_url_batch)\n",
    "            \n",
    "                for k in range(batch_size):\n",
    "                    if(Y_preds[k] != Y_curr_url_batch[k]):\n",
    "                        err = err + 1\n",
    "        \n",
    "    \n",
    "            clf.partial_fit(X_curr_url_batch, Y_curr_url_batch, classes=list(range(2))) # Continous fitting of urls and label\n",
    "        print(i)\n",
    "        print(err / X_curr_day.shape[0])\n",
    "        err = 0\n",
    "\n",
    "end = datetime.now().time() # time object\n",
    "print(\"end =\", end)\n",
    "    # batch size 100, first 15 days\n",
    "    # 0.0486875 -> 0.0241 (0.02105 day14)\n",
    "    \n",
    "    # batch size 100, all days (except 45:broken)\n",
    "    # 0.0486875 -> 0.0154 ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed9da3",
   "metadata": {},
   "source": [
    "**evaluate accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee33619",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m      3\u001b[0m Y_test_preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mX_test\u001b[49m)): \u001b[38;5;66;03m## Looping through test batches for making predictions\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     Y_preds \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test[j])\n\u001b[1;32m      6\u001b[0m     Y_test_preds\u001b[38;5;241m.\u001b[39mextend(Y_preds\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Y_test_preds = []\n",
    "for j in range(len(X_test)): ## Looping through test batches for making predictions\n",
    "    Y_preds = clf.predict(X_test[j])\n",
    "    Y_test_preds.extend(Y_preds.tolist())\n",
    "\n",
    "# flatten y_test\n",
    "Y_test = [element for sublist in Y_test for element in sublist]\n",
    "print(\"Test Accuracy      : {}\".format(accuracy_score(Y_test, Y_test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a66556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incremental learns classifier (must have partial_fit() function)\n",
    "# returns an array of cumulative error rates for each day\n",
    "def learn_incremental(clf, batch_size = 1000):\n",
    "    \n",
    "    error_rates = []\n",
    "    num_of_days = 120\n",
    "    err = 0\n",
    "    \n",
    "    for curr_day in range(num_of_days): # looping through days\n",
    "    \n",
    "        # change X to row format for faster slicing row-wise.\n",
    "        X_curr_day = X[i].tocsr()\n",
    "    \n",
    "        # split the data in slices of batch_size\n",
    "        batches_amount = int(X_curr_day.shape[0] / batch_size)\n",
    "        Y_curr_day = np.array_split(Y[i], batches_amount)\n",
    "    \n",
    "        for j in range(batches_amount): # looping through individual urls\n",
    "            select_ind = np.arange(j * batch_size, (j+1) * batch_size)\n",
    "        \n",
    "            X_curr_url_batch, Y_curr_url_batch = X_curr_day[select_ind,:], Y_curr_day[j] \n",
    "        \n",
    "    \n",
    "            # flatten y to 1d\n",
    "            Y_curr_url_batch = Y_curr_url_batch.ravel()\n",
    "        \n",
    "            if (j > 0):\n",
    "                Y_preds = clf.predict(X_curr_url_batch)\n",
    "            \n",
    "                for k in range(batch_size):\n",
    "                    if(Y_preds[k] != Y_curr_url_batch[k]):\n",
    "                        err = err + 1\n",
    "        \n",
    "    \n",
    "            clf.partial_fit(X_curr_url_batch, Y_curr_url_batch, classes=list(range(2))) # Continous fitting of urls and label\n",
    "        \n",
    "        print(\"Error-rate Day {}   : {}\".format(curr_day, err / X_curr_day.shape[0]))\n",
    "        error_rates.append(err / X_curr_day.shape[0])\n",
    "        err = 0\n",
    "    return error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "546a3c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error-rate Day 0   : 0.0426\n",
      "Error-rate Day 1   : 0.0254\n",
      "Error-rate Day 2   : 0.02015\n",
      "Error-rate Day 3   : 0.0162\n",
      "Error-rate Day 4   : 0.01475\n",
      "Error-rate Day 5   : 0.0121\n",
      "Error-rate Day 6   : 0.0126\n",
      "Error-rate Day 7   : 0.01075\n",
      "Error-rate Day 8   : 0.01045\n",
      "Error-rate Day 9   : 0.0087\n",
      "Error-rate Day 10   : 0.008\n",
      "Error-rate Day 11   : 0.01\n",
      "Error-rate Day 12   : 0.00805\n",
      "Error-rate Day 13   : 0.0053\n",
      "Error-rate Day 14   : 0.0064\n",
      "Error-rate Day 15   : 0.0053\n",
      "Error-rate Day 16   : 0.00435\n",
      "Error-rate Day 17   : 0.0058\n",
      "Error-rate Day 18   : 0.0049\n",
      "Error-rate Day 19   : 0.00525\n",
      "Error-rate Day 20   : 0.004\n",
      "Error-rate Day 21   : 0.00385\n",
      "Error-rate Day 22   : 0.0027\n",
      "Error-rate Day 23   : 0.00365\n",
      "Error-rate Day 24   : 0.00435\n",
      "Error-rate Day 25   : 0.00315\n",
      "Error-rate Day 26   : 0.0046\n",
      "Error-rate Day 27   : 0.00405\n",
      "Error-rate Day 28   : 0.00295\n",
      "Error-rate Day 29   : 0.00305\n",
      "Error-rate Day 30   : 0.00205\n",
      "Error-rate Day 31   : 0.0041\n",
      "Error-rate Day 32   : 0.00435\n",
      "Error-rate Day 33   : 0.00315\n",
      "Error-rate Day 34   : 0.0037\n",
      "Error-rate Day 35   : 0.00315\n",
      "Error-rate Day 36   : 0.00275\n",
      "Error-rate Day 37   : 0.0031\n",
      "Error-rate Day 38   : 0.00245\n",
      "Error-rate Day 39   : 0.0023\n",
      "Error-rate Day 40   : 0.0024\n",
      "Error-rate Day 41   : 0.00235\n",
      "Error-rate Day 42   : 0.0011\n",
      "Error-rate Day 43   : 0.00205\n",
      "Error-rate Day 44   : 0.00185\n",
      "Error-rate Day 45   : 0.0012\n",
      "Error-rate Day 46   : 0.00175\n",
      "Error-rate Day 47   : 0.00075\n",
      "Error-rate Day 48   : 0.00045\n",
      "Error-rate Day 49   : 0.00065\n",
      "Error-rate Day 50   : 0.0008\n",
      "Error-rate Day 51   : 0.0012\n",
      "Error-rate Day 52   : 0.0008\n",
      "Error-rate Day 53   : 0.0008\n",
      "Error-rate Day 54   : 0.0008\n",
      "Error-rate Day 55   : 0.0008\n",
      "Error-rate Day 56   : 0.0002\n",
      "Error-rate Day 57   : 0.00035\n",
      "Error-rate Day 58   : 0.0007\n",
      "Error-rate Day 59   : 0.00015\n",
      "Error-rate Day 60   : 0.0006\n",
      "Error-rate Day 61   : 0.00085\n",
      "Error-rate Day 62   : 0.0006\n",
      "Error-rate Day 63   : 0.00055\n",
      "Error-rate Day 64   : 0.0\n",
      "Error-rate Day 65   : 0.0\n",
      "Error-rate Day 66   : 0.0\n",
      "Error-rate Day 67   : 0.0\n",
      "Error-rate Day 68   : 0.0\n",
      "Error-rate Day 69   : 0.0\n",
      "Error-rate Day 70   : 0.0\n",
      "Error-rate Day 71   : 0.0\n",
      "Error-rate Day 72   : 0.0\n",
      "Error-rate Day 73   : 0.0\n",
      "Error-rate Day 74   : 0.0\n",
      "Error-rate Day 75   : 0.0\n",
      "Error-rate Day 76   : 0.0\n",
      "Error-rate Day 77   : 0.0\n",
      "Error-rate Day 78   : 0.0\n",
      "Error-rate Day 79   : 0.0\n",
      "Error-rate Day 80   : 0.0\n",
      "Error-rate Day 81   : 0.0\n",
      "Error-rate Day 82   : 0.0\n",
      "Error-rate Day 83   : 0.0\n",
      "Error-rate Day 84   : 0.0\n",
      "Error-rate Day 85   : 0.0\n",
      "Error-rate Day 86   : 0.0\n",
      "Error-rate Day 87   : 0.0\n",
      "Error-rate Day 88   : 0.0\n",
      "Error-rate Day 89   : 0.0\n",
      "Error-rate Day 90   : 0.0\n",
      "Error-rate Day 91   : 0.0\n",
      "Error-rate Day 92   : 0.0\n",
      "Error-rate Day 93   : 0.0\n",
      "Error-rate Day 94   : 0.0\n",
      "Error-rate Day 95   : 0.0\n",
      "Error-rate Day 96   : 0.0\n",
      "Error-rate Day 97   : 0.0\n",
      "Error-rate Day 98   : 0.0\n",
      "Error-rate Day 99   : 0.0\n",
      "Error-rate Day 100   : 0.0\n",
      "Error-rate Day 101   : 0.0\n",
      "Error-rate Day 102   : 0.0\n",
      "Error-rate Day 103   : 0.0\n",
      "Error-rate Day 104   : 0.0\n",
      "Error-rate Day 105   : 0.0\n",
      "Error-rate Day 106   : 0.0\n",
      "Error-rate Day 107   : 0.0\n",
      "Error-rate Day 108   : 0.0\n",
      "Error-rate Day 109   : 0.0\n",
      "Error-rate Day 110   : 0.0\n",
      "Error-rate Day 111   : 0.0\n",
      "Error-rate Day 112   : 0.0\n",
      "Error-rate Day 113   : 0.0\n",
      "Error-rate Day 114   : 0.0\n",
      "Error-rate Day 115   : 0.0\n",
      "Error-rate Day 116   : 0.0\n",
      "Error-rate Day 117   : 0.0\n",
      "Error-rate Day 118   : 0.0\n",
      "Error-rate Day 119   : 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron(random_state = 123)\n",
    "\n",
    "error_rates = learn_incremental(clf, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e33c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
